"""
MinerU è¿œç¨‹è§£æç»“æœå¤„ç†å™¨

åŠŸèƒ½ï¼š
- ä¸‹è½½ MinerU è§£æç»“æœå‹ç¼©åŒ…
- è§£æ Markdown æ–‡æ¡£
- æ”¯æŒä¸‰ç§å¤„ç†æ¨¡å¼ï¼šoffï¼ˆä»… Markdownï¼‰/ selectiveï¼ˆé€‰æ‹©æ€§ VLMï¼‰/ fullï¼ˆå®Œæ•´ RAG-Anythingï¼‰
- ç›´æ¥å°†å†…å®¹æ’å…¥ LightRAG
- ä¼˜åŒ–äº†ç»“æœå¤„ç†æµç¨‹ï¼Œé¿å…é‡å¤è§£æ
"""

import os
import aiohttp
import zipfile
import tempfile
from typing import Optional, List, Dict, Any

from src.logger import logger


class MinerUResultProcessor:
    """MinerU è§£æç»“æœå¤„ç†å™¨"""
    
    def __init__(self):
        self.temp_dir = tempfile.gettempdir()
    
    async def download_result_zip(self, zip_url: str) -> str:
        """
        ä¸‹è½½ MinerU è§£æç»“æœå‹ç¼©åŒ…
        
        Args:
            zip_url: ç»“æœ ZIP æ–‡ä»¶ URL
        
        Returns:
            str: æœ¬åœ° ZIP æ–‡ä»¶è·¯å¾„
        
        Raises:
            Exception: ä¸‹è½½å¤±è´¥
        """
        try:
            zip_path = os.path.join(self.temp_dir, f"mineru_{os.path.basename(zip_url)}")
            
            logger.info(f"Downloading MinerU result: {zip_url}")
            
            async with aiohttp.ClientSession() as session:
                async with session.get(zip_url, timeout=aiohttp.ClientTimeout(total=300)) as response:
                    if response.status != 200:
                        raise Exception(f"Download failed with status {response.status}")
                    
                    # å†™å…¥æ–‡ä»¶
                    with open(zip_path, 'wb') as f:
                        async for chunk in response.content.iter_chunked(8192):
                            f.write(chunk)
            
            logger.info(f"âœ“ Downloaded result ZIP: {zip_path}")
            return zip_path
        
        except Exception as e:
            logger.error(f"Failed to download result ZIP: {e}")
            raise
    
    def extract_markdown_files(self, zip_path: str) -> List[str]:
        """
        ä»å‹ç¼©åŒ…ä¸­æå– Markdown æ–‡ä»¶

        Args:
            zip_path: ZIP æ–‡ä»¶è·¯å¾„

        Returns:
            List[str]: æå–çš„ Markdown æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            extracted_files = []
            extract_dir = os.path.join(self.temp_dir, f"mineru_extracted_{os.path.basename(zip_path)}")
            os.makedirs(extract_dir, exist_ok=True)

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
                for file_info in zip_ref.filelist:
                    if file_info.filename.endswith('.md'):
                        zip_ref.extract(file_info, extract_dir)
                        md_file = os.path.join(extract_dir, file_info.filename)
                        extracted_files.append(md_file)
                        logger.info(f"Extracted: {file_info.filename}")

            logger.info(f"âœ“ Extracted {len(extracted_files)} Markdown files from {zip_path}")
            return extracted_files

        except Exception as e:
            logger.error(f"Failed to extract Markdown files: {e}")
            raise

    def extract_content_list(self, zip_path: str) -> tuple[List[Dict[str, Any]], str]:
        """
        ä» MinerU ZIP å‹ç¼©åŒ…ä¸­æå– content_list.json
        ä½¿ç”¨ RAG-Anything åŸç”Ÿçš„ _read_output_files æ–¹æ³•

        æ”¯æŒä¸¤ç§ MinerU è¾“å‡ºæ ¼å¼ï¼š
        - Local æ¨¡å¼ï¼š{file_stem}_content_list.json
        - Remote API æ¨¡å¼ï¼š{uuid}_content_list.json

        Args:
            zip_path: ZIP æ–‡ä»¶è·¯å¾„

        Returns:
            tuple[List[Dict[str, Any]], str]: (content_list æ•°æ®, æå–ç›®å½•è·¯å¾„)

        Raises:
            Exception: æå–å¤±è´¥æˆ– content_list.json ä¸å­˜åœ¨
        """
        try:
            extract_dir = os.path.join(self.temp_dir, f"mineru_full_{os.path.basename(zip_path)}")
            os.makedirs(extract_dir, exist_ok=True)

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # æå–æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…å« content_list.json + images/ï¼‰
                zip_ref.extractall(extract_dir)
                logger.info(f"âœ“ Extracted all files to: {extract_dir}")

            # ä½¿ç”¨ RAG-Anything åŸç”Ÿæ–¹æ³•è¯»å– MinerU è¾“å‡º
            # è¿™ä¼šè‡ªåŠ¨å¤„ç†æ–‡ä»¶ååŒ¹é…å’Œè·¯å¾„è½¬æ¢
            from pathlib import Path
            from raganything.parser import MineruParser

            # 1. æŸ¥æ‰¾æ–‡ä»¶å‰ç¼€ï¼ˆé€šè¿‡ _content_list.json åç¼€ï¼‰
            file_stem = None
            for _, _, files in os.walk(extract_dir):
                for file in files:
                    if file.endswith("_content_list.json"):
                        file_stem = file.replace("_content_list.json", "")
                        logger.info(f"âœ“ Detected file_stem from MinerU output: {file_stem}")
                        break
                if file_stem:
                    break

            if not file_stem:
                raise Exception("No content_list.json file found in ZIP")

            # 2. ä½¿ç”¨ RAG-Anything åŸç”Ÿçš„ _read_output_files æ–¹æ³•
            # è¿™ä¼šè‡ªåŠ¨å¤„ç†ï¼š
            # - æ–‡ä»¶åæ ¼å¼ ({file_stem}_content_list.json)
            # - å›¾ç‰‡è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            # - æ”¯æŒå­ç›®å½•ç»“æ„ï¼ˆlocal vs remote æ¨¡å¼ï¼‰
            content_list, _ = MineruParser._read_output_files(
                output_dir=Path(extract_dir),
                file_stem=file_stem,
                method="auto"
            )

            logger.info(f"âœ“ Loaded content_list using RAG-Anything native method: {len(content_list)} items")
            return content_list, extract_dir

        except Exception as e:
            logger.error(f"Failed to extract content_list.json: {e}")
            raise

    @staticmethod
    def is_important(item: Dict[str, Any], threshold: float = 0.5) -> bool:
        """
        åˆ¤æ–­å›¾è¡¨æ˜¯å¦é‡è¦ï¼ˆç”¨äº selective æ¨¡å¼ï¼‰

        Args:
            item: content_list ä¸­çš„ä¸€é¡¹
            threshold: bbox é¢ç§¯é˜ˆå€¼ï¼ˆ0-1ï¼Œé»˜è®¤ 0.5ï¼‰

        Returns:
            bool: æ˜¯å¦ä¸ºé‡è¦å›¾è¡¨
        """
        # ç­–ç•¥ 1ï¼šæœ‰æ ‡é¢˜çš„å›¾è¡¨ï¼ˆé€šå¸¸æ›´é‡è¦ï¼‰
        if item.get("image_caption") or item.get("table_caption"):
            return True

        # ç­–ç•¥ 2ï¼šå¤§å°ºå¯¸å›¾è¡¨ï¼ˆbbox é¢ç§¯ > thresholdï¼‰
        bbox = item.get("bbox")
        if bbox and len(bbox) == 4:
            # MinerU bbox æ ¼å¼ï¼š[x1, y1, x2, y2]ï¼Œåæ ‡èŒƒå›´ 0-1000ï¼ˆå½’ä¸€åŒ–ï¼‰
            area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]) / (1000 * 1000)
            if area > threshold:
                return True

        # ç­–ç•¥ 3ï¼šé¦–é¡µå†…å®¹ï¼ˆé€šå¸¸åŒ…å«å…³é”®ä¿¡æ¯ï¼‰
        if item.get("page_idx", 999) < 3:
            return True

        return False
    
    async def process_markdown_content(self, markdown_files: List[str], lightrag_instance, original_filename: str = "document", doc_id: str = None) -> int:
        """
        å¤„ç† Markdown æ–‡ä»¶ï¼Œå°†å†…å®¹æ’å…¥ LightRAG

        Args:
            markdown_files: Markdown æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            lightrag_instance: LightRAG å®ä¾‹
            original_filename: åŸå§‹æ–‡ä»¶åï¼ˆç”¨äºå‚è€ƒæ–‡çŒ®ç”Ÿæˆï¼‰
            doc_id: ç”¨æˆ·æŒ‡å®šçš„æ–‡æ¡£ IDï¼ˆç”¨äºå»é‡æ£€æµ‹ï¼‰

        Returns:
            int: æˆåŠŸæ’å…¥çš„æ–‡ä»¶æ•°é‡
        """
        success_count = 0
        
        for md_file in markdown_files:
            try:
                # è¯»å– Markdown æ–‡ä»¶
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if not content or len(content.strip()) == 0:
                    logger.warning(f"Empty Markdown file: {md_file}")
                    continue
                
                # ç›´æ¥æ’å…¥åˆ° LightRAGï¼ˆå¸¦ doc_idï¼‰
                logger.info(f"Inserting Markdown content to LightRAG: {os.path.basename(md_file)} ({len(content)} chars)")
                await lightrag_instance.ainsert(content, ids=doc_id, file_paths=original_filename)

                success_count += 1
                logger.info(f"âœ“ Successfully inserted: {os.path.basename(md_file)} (file: {original_filename})")
            
            except Exception as e:
                logger.error(f"Failed to process Markdown file {md_file}: {e}")
        
        return success_count
    
    async def process_mineru_result(
        self,
        result,  # TaskResult å¯¹è±¡
        lightrag_instance,
        mode: str = "off",
        vision_func=None,
        original_filename: str = "document",
        importance_threshold: float = 0.5,
        rag_config: Optional[Dict[str, Any]] = None,
        doc_id: str = None  # ğŸ†• ç”¨æˆ·æŒ‡å®šçš„æ–‡æ¡£ ID
    ) -> Dict[str, Any]:
        """
        ä¸€ç«™å¼å¤„ç† MinerU è§£æç»“æœï¼ˆæ”¯æŒä¸‰ç§æ¨¡å¼ï¼‰

        Args:
            result: MinerU TaskResult å¯¹è±¡ï¼ˆåŒ…å« full_zip_urlï¼‰
            lightrag_instance: LightRAG å®ä¾‹
            mode: å¤„ç†æ¨¡å¼ ("off" / "selective" / "full")
            vision_func: VLM å‡½æ•°ï¼ˆmode=selective/full æ—¶å¿…éœ€ï¼‰
            original_filename: åŸå§‹æ–‡ä»¶åï¼ˆç”¨äº RAG-Anythingï¼‰
            importance_threshold: é‡è¦æ€§é˜ˆå€¼ï¼ˆmode=selective æ—¶ä½¿ç”¨ï¼‰
            rag_config: RAG-Anything é…ç½®å­—å…¸ï¼ˆmode=full æ—¶ä½¿ç”¨ï¼‰
            doc_id: ç”¨æˆ·æŒ‡å®šçš„æ–‡æ¡£ IDï¼ˆç”¨äºå»é‡æ£€æµ‹ï¼‰

        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœæ‘˜è¦
        """
        try:
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
            if not result.is_completed:
                raise Exception(f"MinerU task failed: {result.error_message}")

            if not result.full_zip_url:
                raise Exception("MinerU result missing full_zip_url")

            # 1. ä¸‹è½½ç»“æœå‹ç¼©åŒ…
            zip_path = await self.download_result_zip(result.full_zip_url)

            # æ ¹æ®æ¨¡å¼é€‰æ‹©å¤„ç†ç­–ç•¥
            if mode == "off":
                # æ¨¡å¼ 1ï¼šä»… Markdownï¼ˆå½“å‰æ–¹æ¡ˆï¼‰
                return await self._process_markdown_only(zip_path, lightrag_instance, result.task_id, original_filename, doc_id=doc_id)

            elif mode == "selective":
                # æ¨¡å¼ 2ï¼šæ··åˆæ¨¡å¼ï¼ˆMarkdown + é€‰æ‹©æ€§ VLMï¼‰
                return await self._process_selective_mode(
                    zip_path, lightrag_instance, vision_func,
                    original_filename, importance_threshold, result.task_id, doc_id=doc_id
                )

            elif mode == "full":
                # æ¨¡å¼ 3ï¼šå®Œæ•´ RAG-Anything å¤„ç†
                return await self._process_full_mode(
                    zip_path, lightrag_instance, vision_func,
                    original_filename, rag_config, result.task_id
                )

            else:
                raise ValueError(f"Invalid mode: {mode}. Must be 'off', 'selective', or 'full'")

        except Exception as e:
            logger.error(f"Failed to process MinerU result: {e}")
            raise

    async def _process_markdown_only(
        self, zip_path: str, lightrag_instance, task_id: str, original_filename: str = "document", doc_id: str = None
    ) -> Dict[str, Any]:
        """æ¨¡å¼ 1ï¼šä»…æå– Markdown æ–‡ä»¶å¹¶æ’å…¥ï¼ˆæœ€å¿«ï¼‰"""
        try:
            logger.info(f"[Task {task_id}] Processing with mode=off (Markdown only)")

            # 1. æå– Markdown æ–‡ä»¶
            markdown_files = self.extract_markdown_files(zip_path)

            if not markdown_files:
                raise Exception("No Markdown files found in result")

            # 2. æ’å…¥ LightRAGï¼ˆä¼ é€’ doc_idï¼‰
            success_count = await self.process_markdown_content(markdown_files, lightrag_instance, original_filename, doc_id=doc_id)

            # 3. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files(zip_path, markdown_files)

            logger.info(f"âœ“ [Task {task_id}] Successfully processed: {success_count}/{len(markdown_files)} files inserted")

            return {
                "status": "success",
                "mode": "off",
                "files_processed": success_count,
                "total_files": len(markdown_files),
                "task_id": task_id
            }

        except Exception:
            # æ¸…ç†å¤±è´¥æ—¶ä¹Ÿè¦åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files(zip_path, [])
            raise

    async def _process_selective_mode(
        self, zip_path: str, lightrag_instance, vision_func,
        original_filename: str, threshold: float, task_id: str, doc_id: str = None
    ) -> Dict[str, Any]:
        """æ¨¡å¼ 2ï¼šMarkdown + é€‰æ‹©æ€§ VLMï¼ˆå¹³è¡¡æ€§èƒ½å’Œè´¨é‡ï¼‰"""
        try:
            logger.info(f"[Task {task_id}] Processing with mode=selective (threshold={threshold})")

            if not vision_func:
                logger.warning(f"[Task {task_id}] vision_func is None, fallback to off mode")
                return await self._process_markdown_only(zip_path, lightrag_instance, task_id, original_filename, doc_id=doc_id)

            # 1. å¿«é€Ÿè·¯å¾„ï¼šæå–å¹¶æ’å…¥ Markdownï¼ˆä¼ é€’ doc_idï¼‰
            markdown_files = self.extract_markdown_files(zip_path)
            if markdown_files:
                await self.process_markdown_content(markdown_files, lightrag_instance, original_filename, doc_id=doc_id)
                logger.info(f"âœ“ [Task {task_id}] Markdown inserted ({len(markdown_files)} files)")

            # 2. æå– content_list.json å’Œå›¾ç‰‡
            content_list, extract_dir = self.extract_content_list(zip_path)

            # 3. è¿‡æ»¤é‡è¦å›¾è¡¨
            important_items = [
                item for item in content_list
                if item.get("type") in ["image", "table"] and self.is_important(item, threshold)
            ]

            logger.info(f"[Task {task_id}] Found {len(important_items)}/{len(content_list)} important visuals")

            if not important_items:
                # æ²¡æœ‰é‡è¦å›¾è¡¨ï¼Œç›´æ¥è¿”å›
                self._cleanup_temp_files_full(zip_path, extract_dir)
                return {
                    "status": "success",
                    "mode": "selective",
                    "files_processed": len(markdown_files),
                    "visuals_processed": 0,
                    "task_id": task_id
                }

            # 4. ä»…å¤„ç†é‡è¦å›¾è¡¨ï¼ˆä¸é‡å¤æ’å…¥æ–‡æœ¬ï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦åˆ›å»º RAGAnything å®ä¾‹ï¼Œç›´æ¥ä½¿ç”¨æ¨¡æ€å¤„ç†å™¨
            visual_count = 0
            for item in important_items:
                try:
                    # ä½¿ç”¨ RAG-Anything çš„æ¨¡æ€å¤„ç†å™¨
                    from raganything.modalprocessors import ImageModalProcessor, TableModalProcessor

                    if item["type"] == "image":
                        processor = ImageModalProcessor(
                            lightrag=lightrag_instance,
                            modal_caption_func=vision_func
                        )
                    else:  # table
                        processor = TableModalProcessor(
                            lightrag=lightrag_instance,
                            modal_caption_func=vision_func
                        )

                    # å¤„ç†å•ä¸ªå¤šæ¨¡æ€å†…å®¹
                    await processor.process_multimodal_content(
                        modal_content=item,
                        content_type=item["type"],
                        file_path=original_filename,
                        entity_name=f"{original_filename}_{item.get('type')}_{item.get('page_idx')}",
                        item_info=item
                    )

                    visual_count += 1
                    logger.info(f"âœ“ [Task {task_id}] Processed {item['type']} on page {item.get('page_idx')}")

                except Exception as exc:
                    logger.warning(f"[Task {task_id}] Failed to process {item['type']}: {exc}")

            # 6. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files_full(zip_path, extract_dir)

            logger.info(f"âœ“ [Task {task_id}] Selective mode completed: {visual_count} visuals processed")

            return {
                "status": "success",
                "mode": "selective",
                "files_processed": len(markdown_files),
                "visuals_processed": visual_count,
                "visuals_total": len(important_items),
                "task_id": task_id
            }

        except Exception:
            self._cleanup_temp_files_full(zip_path, "")
            raise

    async def _process_full_mode(
        self, zip_path: str, lightrag_instance, vision_func,
        original_filename: str, rag_config: Optional[Dict[str, Any]], task_id: str
    ) -> Dict[str, Any]:
        """æ¨¡å¼ 3ï¼šå®Œæ•´ RAG-Anything å¤„ç†ï¼ˆæœ€é«˜è´¨é‡ï¼‰"""
        try:
            logger.info(f"[Task {task_id}] Processing with mode=full (RAG-Anything)")

            if not vision_func:
                logger.warning(f"[Task {task_id}] vision_func is None, fallback to off mode")
                return await self._process_markdown_only(zip_path, lightrag_instance, task_id, original_filename)

            # 1. æå– content_list.json å’Œå›¾ç‰‡
            content_list, extract_dir = self.extract_content_list(zip_path)

            # 2. é…ç½® RAG-Anything
            from raganything import RAGAnything, RAGAnythingConfig

            # åˆå¹¶ç”¨æˆ·é…ç½®å’Œé»˜è®¤é…ç½®
            default_config = {
                "working_dir": "./rag_local_storage",
                "parser": "mineru",
                "content_format": "minerU",
                "enable_image_processing": True,
                "enable_table_processing": True,
                "enable_equation_processing": True,
                # ä¸Šä¸‹æ–‡å¢å¼ºé…ç½®
                "context_window": 2,
                "context_mode": "page",
                "max_context_tokens": 3000,
                "include_headers": True,
                "include_captions": True,
                "context_filter_content_types": ["text", "image", "table"],
            }

            if rag_config:
                default_config.update(rag_config)

            config = RAGAnythingConfig(**default_config)

            rag_anything = RAGAnything(
                config=config,
                lightrag=lightrag_instance,
                vision_model_func=vision_func
            )

            # 3. è®¾ç½® MinerU content_list ä¸ºä¸Šä¸‹æ–‡æº
            rag_anything.set_content_source_for_context(content_list, "minerU")

            # 4. ä½¿ç”¨ RAG-Anything æ’å…¥å®Œæ•´å†…å®¹
            await rag_anything.insert_content_list(
                content_list=content_list,
                file_path=original_filename
            )

            logger.info(f"âœ“ [Task {task_id}] RAG-Anything processing completed ({len(content_list)} items)")

            # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files_full(zip_path, extract_dir)

            return {
                "status": "success",
                "mode": "full",
                "items_processed": len(content_list),
                "task_id": task_id
            }

        except Exception:
            self._cleanup_temp_files_full(zip_path, "")
            raise

    def _cleanup_temp_files(self, zip_path: str, markdown_files: List[str]):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆä»… Markdown æ¨¡å¼ï¼‰"""
        try:
            # åˆ é™¤ ZIP æ–‡ä»¶
            if os.path.exists(zip_path):
                os.remove(zip_path)
                logger.info(f"Cleaned up: {zip_path}")

            # åˆ é™¤æå–çš„æ–‡ä»¶å’Œç›®å½•
            for md_file in markdown_files:
                if os.path.exists(md_file):
                    os.remove(md_file)
                    logger.info(f"Cleaned up: {md_file}")

                # åˆ é™¤çˆ¶ç›®å½•ï¼ˆå¦‚æœä¸ºç©ºï¼‰
                parent_dir = os.path.dirname(md_file)
                try:
                    if os.path.exists(parent_dir) and not os.listdir(parent_dir):
                        os.rmdir(parent_dir)
                except:
                    pass

        except Exception as e:
            logger.warning(f"Failed to cleanup temp files: {e}")

    def _cleanup_temp_files_full(self, zip_path: str, extract_dir: str):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå®Œæ•´æ¨¡å¼ï¼ŒåŒ…å«å›¾ç‰‡ç›®å½•ï¼‰"""
        try:
            import shutil

            # åˆ é™¤ ZIP æ–‡ä»¶
            if os.path.exists(zip_path):
                os.remove(zip_path)
                logger.info(f"Cleaned up: {zip_path}")

            # åˆ é™¤æå–ç›®å½•ï¼ˆåŒ…å«æ‰€æœ‰æ–‡ä»¶ï¼‰
            if extract_dir and os.path.exists(extract_dir):
                shutil.rmtree(extract_dir)
                logger.info(f"Cleaned up directory: {extract_dir}")

        except Exception as e:
            logger.warning(f"Failed to cleanup temp files: {e}")


# å…¨å±€å¤„ç†å™¨å®ä¾‹
_processor = None


def get_result_processor() -> MinerUResultProcessor:
    """è·å–ç»“æœå¤„ç†å™¨å•ä¾‹"""
    global _processor
    if _processor is None:
        _processor = MinerUResultProcessor()
    return _processor