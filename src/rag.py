import os
from dotenv import load_dotenv
import logging
from contextlib import asynccontextmanager
from functools import partial

# -- ä» raganything_example.py æŠ„è¿‡æ¥çš„ç»„ä»¶ --
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc
from lightrag.kg.shared_storage import initialize_pipeline_status
from raganything import RAGAnything, RAGAnythingConfig

# å¯¼å…¥ rerank å‡½æ•°
try:
    from lightrag.rerank import cohere_rerank
except ImportError:
    cohere_rerank = None
    logging.warning("lightrag.rerank not available, rerankåŠŸèƒ½å°†è¢«ç¦ç”¨")

# --- é…ç½® ---
load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- å…¨å±€å®ä¾‹ï¼ˆå•ä¸€ LightRAG æ¶æ„ï¼‰---
global_lightrag_instance = None  # å•ä¸€å…±äº«çš„ LightRAG å®ä¾‹ï¼ˆæ ¸å¿ƒçŸ¥è¯†å›¾è°±ï¼‰
rag_instance_mineru = None  # MinerU: å¼ºå¤§å¤šæ¨¡æ€è§£æå™¨ï¼Œå…±äº« LightRAG
rag_instance_docling = None  # Docling: è½»é‡å¿«é€Ÿè§£æå™¨ï¼Œå…±äº« LightRAG
rag_instance = None  # é»˜è®¤å®ä¾‹ï¼ˆå‘åå…¼å®¹ï¼‰

# --- RAG å®ä¾‹ç®¡ç† ---
@asynccontextmanager
async def lifespan(app):
    # å¯åŠ¨æ—¶åˆ›å»ºå•ä¸€ LightRAG å®ä¾‹ + å¤šè§£æå™¨æ¶æ„
    global global_lightrag_instance, rag_instance, rag_instance_mineru, rag_instance_docling
    logger.info("Starting up: Single LightRAG + Multiple Parsers architecture...")

    # è¯»å– LLM å’Œ Embedding é…ç½®
    ark_api_key = os.getenv("ARK_API_KEY")
    ark_base_url = os.getenv("ARK_BASE_URL")
    ark_model = os.getenv("ARK_MODEL", "seed-1-6-250615")
    
    sf_api_key = os.getenv("SF_API_KEY")
    sf_base_url = os.getenv("SF_BASE_URL")
    sf_embedding_model = os.getenv("SF_EMBEDDING_MODEL", "Qwen/Qwen3-Embedding-8B")
    
    rerank_model = os.getenv("RERANK_MODEL", "")  # å¯é€‰é…ç½®
    
    # éªŒè¯å¿…éœ€é…ç½®
    if not ark_api_key:
        raise RuntimeError("ARK_API_KEY is not set!")
    if not sf_api_key:
        raise RuntimeError("SF_API_KEY is not set!")
    if not sf_base_url:
        raise RuntimeError("SF_BASE_URL is not set!")
    if not ark_base_url:
        raise RuntimeError("ARK_BASE_URL is not set!")
    
    # è¯»å– LightRAG æŸ¥è¯¢ä¼˜åŒ–å‚æ•°ï¼ˆä¼˜åŒ– MAX_ASYNC æå‡å¹¶å‘æ€§èƒ½ï¼‰
    top_k = int(os.getenv("TOP_K", "20"))
    chunk_top_k = int(os.getenv("CHUNK_TOP_K", "10"))
    max_async = int(os.getenv("MAX_ASYNC", "8"))  # ä» 4 æå‡åˆ° 8ï¼Œä¼˜åŒ–å®ä½“åˆå¹¶æ€§èƒ½
    max_parallel_insert = int(os.getenv("MAX_PARALLEL_INSERT", "2"))
    max_entity_tokens = int(os.getenv("MAX_ENTITY_TOKENS", "6000"))
    max_relation_tokens = int(os.getenv("MAX_RELATION_TOKENS", "8000"))
    max_total_tokens = int(os.getenv("MAX_TOTAL_TOKENS", "30000"))
    
    # è¾“å‡ºé…ç½®ä¿¡æ¯
    logger.info("=" * 70)
    logger.info("ğŸ“Š RAG API é…ç½®æ€»è§ˆ")
    logger.info("=" * 70)
    logger.info(f"ğŸ¤– LLM: {ark_model}")
    logger.info(f"ğŸ”¤ Embedding: {sf_embedding_model} (dim={4096})")
    logger.info(f"ğŸ¯ Rerank: {rerank_model or 'Disabled'}")
    logger.info(f"ğŸ“ˆ Query: top_k={top_k}, chunk_top_k={chunk_top_k}, max_async={max_async}")
    logger.info(f"ğŸ’¾ Tokens: entity={max_entity_tokens}, relation={max_relation_tokens}, total={max_total_tokens}")
    logger.info(f"âš™ï¸  Concurrency: doc_processing=1, parallel_insert={max_parallel_insert}")
    logger.info("=" * 70)

    # 1. å®šä¹‰å…±äº«çš„ LLM å’Œ Embedding å‡½æ•°
    def llm_model_func(prompt, **kwargs):
        return openai_complete_if_cache(
            ark_model, prompt, api_key=ark_api_key, base_url=ark_base_url, **kwargs
        )

    embedding_func = EmbeddingFunc(
        embedding_dim=4096,  # Qwen/Qwen3-Embedding-8B å®é™…è¿”å› 4096 ç»´å‘é‡
        func=lambda texts: openai_embed(
            texts, model=sf_embedding_model, api_key=sf_api_key, base_url=sf_base_url
        ),
    )
    
    def vision_model_func(prompt, **kwargs):
        return openai_complete_if_cache(
            ark_model, prompt, api_key=ark_api_key, base_url=ark_base_url, **kwargs
        )
    
    # é…ç½® Rerank å‡½æ•°ï¼ˆå¯é€‰ï¼Œæå‡æ£€ç´¢ç›¸å…³æ€§ï¼‰
    rerank_func = None
    if rerank_model and cohere_rerank:
        rerank_func = partial(
            cohere_rerank,
            model=rerank_model,  # ä¾‹å¦‚ï¼šQwen/Qwen3-Reranker-8B
            api_key=sf_api_key,  # å¤ç”¨ç¡…åŸºæµåŠ¨çš„ API Key
            base_url=f"{sf_base_url}/rerank"  # ç¡…åŸºæµåŠ¨çš„ Rerank ç«¯ç‚¹
        )
        logger.info(f"âœ“ Rerank enabled with model: {rerank_model}")
    else:
        logger.info("âš  Rerank disabled (RERANK_MODEL not set or cohere_rerank unavailable)")

    # 2. åˆ›å»ºå•ä¸€ LightRAG å®ä¾‹ï¼ˆæ ¸å¿ƒçŸ¥è¯†å›¾è°±ï¼Œæ‰€æœ‰è§£æå™¨å…±äº«ï¼‰
    logger.info("Creating shared LightRAG instance...")
    global_lightrag_instance = LightRAG(
        working_dir="./rag_local_storage",
        llm_model_func=llm_model_func,
        embedding_func=embedding_func,
        llm_model_max_async=max_async,  # ä¼˜åŒ–å¹¶å‘æ€§èƒ½ï¼ˆä» 4 æå‡åˆ° 8ï¼‰
    )
    
    # åˆå§‹åŒ– LightRAG å­˜å‚¨
    await global_lightrag_instance.initialize_storages()
    await initialize_pipeline_status()
    
    # é…ç½® Rerankï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if rerank_func:
        global_lightrag_instance.rerank_model_func = rerank_func
        logger.info("âœ“ LightRAG Rerank configured")
    
    logger.info("âœ“ Shared LightRAG instance created successfully")

    # 3. åˆ›å»º MinerU è§£æå™¨å®ä¾‹ï¼ˆå…±äº« LightRAGï¼‰
    config_mineru = RAGAnythingConfig(
        working_dir="./rag_local_storage",
        parser="mineru",  # å¼ºå¤§çš„å¤šæ¨¡æ€è§£æ
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )
    rag_instance_mineru = RAGAnything(
        config=config_mineru,
        lightrag=global_lightrag_instance,  # ä¼ å…¥å…±äº«çš„ LightRAG å®ä¾‹
        vision_model_func=vision_model_func,
    )
    logger.info("âœ“ MinerU parser initialized (shares LightRAG instance)")

    # 4. åˆ›å»º Docling è§£æå™¨å®ä¾‹ï¼ˆå…±äº« LightRAGï¼‰
    config_docling = RAGAnythingConfig(
        working_dir="./rag_local_storage",  # å…±äº«ç›¸åŒçš„ working_dir
        parser="docling",  # è½»é‡çº§è§£æå™¨
        enable_image_processing=False,  # Docling ä¸æ”¯æŒå¤šæ¨¡æ€
        enable_table_processing=False,
        enable_equation_processing=False,
    )
    rag_instance_docling = RAGAnything(
        config=config_docling,
        lightrag=global_lightrag_instance,  # ä¼ å…¥å…±äº«çš„ LightRAG å®ä¾‹
        vision_model_func=vision_model_func,
    )
    logger.info("âœ“ Docling parser initialized (shares LightRAG instance)")

    # 5. è®¾ç½®é»˜è®¤å®ä¾‹ä¸º MinerUï¼ˆå‘åå…¼å®¹ï¼‰
    rag_instance = rag_instance_mineru
    
    logger.info("=" * 70)
    logger.info("âœ… Architecture: Single LightRAG + Multiple Parsers")
    logger.info("   - Shared LightRAG: 1 instance (knowledge graph core)")
    logger.info("   - MinerU Parser: for complex multimodal documents")
    logger.info("   - Docling Parser: for simple documents")
    logger.info("   - Direct Query: bypass parsers for 95% text queries")
    logger.info("=" * 70)

    yield  # åº”ç”¨è¿è¡ŒæœŸé—´ä¿æŒå®ä¾‹å¯ç”¨

    # å…³é—­æ—¶æ¸…ç†èµ„æº
    logger.info("Shutting down RAGAnything instance...")
    # å¦‚æœéœ€è¦æ¸…ç†èµ„æºï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 

# è·å– LightRAG å®ä¾‹çš„å‡½æ•°ï¼ˆç”¨äºæŸ¥è¯¢ï¼Œç›´æ¥è®¿é—®çŸ¥è¯†å›¾è°±ï¼‰
def get_lightrag_instance():
    """
    è·å–å…±äº«çš„ LightRAG å®ä¾‹ï¼ˆç”¨äºæŸ¥è¯¢ï¼‰
    
    ä¼˜åŠ¿ï¼š
    - ç»•è¿‡è§£æå™¨ï¼Œç›´æ¥è®¿é—®çŸ¥è¯†å›¾è°±
    - é€‚åˆ 95% çš„çº¯æ–‡æœ¬æŸ¥è¯¢
    - æ€§èƒ½æ›´ä¼˜ï¼Œèµ„æºå ç”¨æ›´ä½
    
    Returns:
        LightRAG: å…±äº«çš„ LightRAG å®ä¾‹
    """
    return global_lightrag_instance

# è·å– RAG å®ä¾‹çš„å‡½æ•°ï¼ˆç”¨äºæ–‡æ¡£æ’å…¥ï¼Œéœ€è¦è§£æå™¨ï¼‰
def get_rag_instance(parser: str = "auto"):
    """
    è·å– RAGAnything å®ä¾‹ï¼ˆç”¨äºæ–‡æ¡£æ’å…¥ï¼‰
    
    Args:
        parser: è§£æå™¨ç±»å‹
            - "mineru": ä½¿ç”¨ MinerUï¼ˆå¼ºå¤§å¤šæ¨¡æ€ï¼Œå†…å­˜å ç”¨å¤§ï¼‰
            - "docling": ä½¿ç”¨ Doclingï¼ˆè½»é‡å¿«é€Ÿï¼Œå†…å­˜å ç”¨å°ï¼‰
            - "auto": è‡ªåŠ¨é€‰æ‹©ï¼ˆé»˜è®¤è¿”å› MinerUï¼‰
    
    Returns:
        RAGAnything: å¯¹åº”çš„è§£æå™¨å®ä¾‹ï¼ˆå…±äº« LightRAGï¼‰
    """
    if parser == "docling":
        return rag_instance_docling
    elif parser == "mineru":
        return rag_instance_mineru
    else:  # "auto" or default
        return rag_instance  # é»˜è®¤ MinerU

def select_parser_by_file(filename: str, file_size: int) -> str:
    """
    æ ¹æ®æ–‡ä»¶ç‰¹å¾æ™ºèƒ½é€‰æ‹©è§£æå™¨
    
    ç­–ç•¥ï¼š
    - çº¯æ–‡æœ¬ (.txt, .md) â†’ è¿”å› "mineru"ï¼ˆå®é™…ä¼šåœ¨å¤„ç†å‡½æ•°ä¸­ç›´æ¥æ’å…¥ LightRAGï¼Œä¸ç»è¿‡è§£æå™¨ï¼‰
    - å›¾ç‰‡æ–‡ä»¶ (.jpg, .png) â†’ MinerUï¼ˆOCRèƒ½åŠ›å¼ºï¼‰
    - PDF/Office å°æ–‡ä»¶ (< 500KB) â†’ Doclingï¼ˆå¿«é€Ÿï¼‰
    - PDF/Office å¤§æ–‡ä»¶ (> 500KB) â†’ MinerUï¼ˆæ›´å¼ºå¤§ï¼‰
    - å…¶ä»– â†’ MinerUï¼ˆé»˜è®¤ï¼‰
    
    æ³¨æ„ï¼š
    - Docling åªæ”¯æŒ PDF å’Œ Office æ ¼å¼ï¼ˆ.pdf, .docx, .xlsx, .pptx, .htmlï¼‰
    - çº¯æ–‡æœ¬æ–‡ä»¶ä¼šè¢«ç‰¹æ®Šå¤„ç†ï¼šç›´æ¥è¯»å–å†…å®¹å¹¶æ’å…¥ LightRAGï¼Œæ— éœ€è§£æå™¨
    
    Args:
        filename: æ–‡ä»¶å
        file_size: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    
    Returns:
        "mineru" æˆ– "docling"
    """
    import os
    ext = os.path.splitext(filename)[1].lower()
    
    # å›¾ç‰‡æ–‡ä»¶ â†’ MinerUï¼ˆéœ€è¦ OCRï¼‰
    if ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff']:
        return "mineru"
    
    # çº¯æ–‡æœ¬æ–‡ä»¶ â†’ MinerUï¼ˆDocling ä¸æ”¯æŒ .txtï¼‰
    if ext in ['.txt', '.md', '.markdown']:
        return "mineru"
    
    # PDF/Office å°æ–‡ä»¶ â†’ Doclingï¼ˆå¿«é€Ÿï¼‰
    if ext in ['.pdf', '.docx', '.xlsx', '.pptx', '.html', '.htm'] and file_size < 500 * 1024:  # < 500KB
        return "docling"
    
    # å¤§æ–‡ä»¶æˆ–å…¶ä»– â†’ MinerU
    return "mineru"
