# RAG API ç”Ÿäº§ç¯å¢ƒè¿ç§»æŒ‡å—

**ç‰ˆæœ¬**: 1.0
**æ›´æ–°æ—¥æœŸ**: 2025-10-23
**ç›®æ ‡**: ä»æ–‡ä»¶å­˜å‚¨è¿ç§»åˆ°å¤–éƒ¨åŒ–å­˜å‚¨ï¼Œæœ€ç»ˆéƒ¨ç½²åˆ° AWS ECS

---

## ğŸ“‹ ç›®å½•

1. [è¿ç§»æ¦‚è§ˆ](#è¿ç§»æ¦‚è§ˆ)
2. [é˜¶æ®µ 1ï¼šDocker Compose å¤–éƒ¨åŒ–å­˜å‚¨](#é˜¶æ®µ-1docker-compose-å¤–éƒ¨åŒ–å­˜å‚¨)
3. [é˜¶æ®µ 2ï¼šAWS æ‰˜ç®¡æœåŠ¡è¿ç§»](#é˜¶æ®µ-2aws-æ‰˜ç®¡æœåŠ¡è¿ç§»)
4. [é˜¶æ®µ 3ï¼šè¿ç§»åˆ° AWS ECS](#é˜¶æ®µ-3è¿ç§»åˆ°-aws-ecs)
5. [æ•°æ®è¿ç§»è„šæœ¬](#æ•°æ®è¿ç§»è„šæœ¬)
6. [å›æ»šæ–¹æ¡ˆ](#å›æ»šæ–¹æ¡ˆ)
7. [ç›‘æ§å’ŒéªŒè¯](#ç›‘æ§å’ŒéªŒè¯)

---

## è¿ç§»æ¦‚è§ˆ

### æ¶æ„æ¼”è¿›è·¯çº¿

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å½“å‰æ¶æ„ï¼ˆdev + main åˆ†æ”¯ï¼‰                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚ â”‚  FastAPI    â”‚                                             â”‚
â”‚ â”‚  å®¹å™¨       â”‚                                             â”‚
â”‚ â”‚  â†“          â”‚                                             â”‚
â”‚ â”‚ æ–‡ä»¶å­˜å‚¨    â”‚                                             â”‚
â”‚ â”‚ (JSON/XML)  â”‚                                             â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“ é˜¶æ®µ 1ï¼ˆ1-2 å‘¨ï¼‰
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Docker Compose å¤–éƒ¨åŒ–ï¼ˆmain åˆ†æ”¯ï¼‰                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚ â”‚  FastAPI    â”‚â”€â”€â”€â†’â”‚Redis â”‚  â”‚Neo4j   â”‚  â”‚Postgresâ”‚        â”‚
â”‚ â”‚  å®¹å™¨       â”‚    â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚                     Docker Compose æœ¬åœ°ç½‘ç»œ                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“ é˜¶æ®µ 2ï¼ˆ2-3 å‘¨ï¼‰
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWS æ‰˜ç®¡æœåŠ¡                                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚ â”‚  FastAPI    â”‚                                             â”‚
â”‚ â”‚  EC2 å®¹å™¨   â”‚                                             â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚       â†“                                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ â”‚ ElastiCache  â”‚ Aurora    â”‚ Neo4j Aura   â”‚                 â”‚
â”‚ â”‚ Redis        â”‚ Serverlessâ”‚ (Managed)    â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“ é˜¶æ®µ 3ï¼ˆ3-4 å‘¨ï¼‰
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWS ECS Fargateï¼ˆæ— çŠ¶æ€å®¹å™¨ï¼‰                                â”‚
â”‚                                                              â”‚
â”‚      ALBï¼ˆè´Ÿè½½å‡è¡¡ï¼‰                                         â”‚
â”‚            â†“                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚   â”‚  ECS Service   â”‚                                        â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                                        â”‚
â”‚   â”‚  â”‚ Task 1   â”‚  â”‚   â† è‡ªåŠ¨æ‰©ç¼©å®¹ï¼ˆ2-10 ä¸ªå®¹å™¨ï¼‰          â”‚
â”‚   â”‚  â”‚ Task 2   â”‚  â”‚                                        â”‚
â”‚   â”‚  â”‚ Task ...â”‚  â”‚                                        â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚            â†“                                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚ â”‚ ElastiCache  â”‚ Aurora    â”‚ Neo4j Aura   â”‚                 â”‚
â”‚ â”‚ Redis        â”‚ Serverlessâ”‚              â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### åˆ†æ”¯ç­–ç•¥

| åˆ†æ”¯ | å­˜å‚¨æ–¹å¼ | ç”¨é€” | æ›´æ–°é¢‘ç‡ |
|------|---------|------|---------|
| **dev** | æ–‡ä»¶å­˜å‚¨ | å¼€å‘ç¯å¢ƒï¼Œå¿«é€Ÿè¿­ä»£ | æ¯å¤© |
| **main** | å¤–éƒ¨å­˜å‚¨ | ç”Ÿäº§ç¯å¢ƒï¼Œç¨³å®šéƒ¨ç½² | æ¯å‘¨ |

---

## é˜¶æ®µ 1ï¼šDocker Compose å¤–éƒ¨åŒ–å­˜å‚¨

**æ—¶é—´**: 1-2 å‘¨
**ç›®æ ‡**: åœ¨ main åˆ†æ”¯å¯ç”¨å¤–éƒ¨å­˜å‚¨æœåŠ¡ï¼ˆRedis + Neo4j + PostgreSQLï¼‰
**ç¯å¢ƒ**: Docker Compose æœ¬åœ°éƒ¨ç½²ï¼ˆEC2 æˆ–æœ¬åœ°æœåŠ¡å™¨ï¼‰

### 1.1 æ›´æ–° docker-compose.yml

åœ¨ `docker-compose.yml` ä¸­æ·»åŠ å¤–éƒ¨å­˜å‚¨æœåŠ¡ï¼š

```yaml
version: '3.8'

services:
  # ==================== åº”ç”¨æœåŠ¡ ====================
  rag-api:
    build:
      context: .
      dockerfile: Dockerfile
      cache_from:
        - type=registry,ref=rag-api-rag-api:latest
    container_name: rag-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    env_file:
      - .env
    volumes:
      # æŒä¹…åŒ–è¾“å‡ºæ–‡ä»¶ï¼ˆä¿ç•™ï¼‰
      - ./output:/app/output
      # æŒä¹…åŒ–æ—¥å¿—ï¼ˆä¿ç•™ï¼‰
      - ./logs:/app/logs
      # æ³¨æ„ï¼šç§»é™¤ rag_local_storage æŒ‚è½½ï¼Œä½¿ç”¨å¤–éƒ¨æ•°æ®åº“
    environment:
      - TZ=Asia/Shanghai
      - PYTHONUNBUFFERED=1
      # å¤–éƒ¨å­˜å‚¨é…ç½®
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=lightrag
      - POSTGRES_USER=lightrag
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    depends_on:
      redis:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - rag-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==================== Redisï¼ˆKV å­˜å‚¨ + ç¼“å­˜ï¼‰====================
  redis:
    image: redis:7-alpine
    container_name: rag-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: >
      redis-server
      --appendonly yes
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag-network

  # ==================== Neo4jï¼ˆå›¾å­˜å‚¨ï¼‰====================
  neo4j:
    image: neo4j:5-community
    container_name: rag-neo4j
    restart: unless-stopped
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD}
      - NEO4J_server_memory_heap_initial__size=512m
      - NEO4J_server_memory_heap_max__size=1G
      - NEO4J_server_memory_pagecache_size=512m
      # å…è®¸ä»å®¹å™¨å¤–è®¿é—®
      - NEO4J_server_default__listen__address=0.0.0.0
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "${NEO4J_PASSWORD}", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - rag-network

  # ==================== PostgreSQLï¼ˆå‘é‡å­˜å‚¨ï¼‰====================
  postgres:
    image: pgvector/pgvector:pg16
    container_name: rag-postgres
    restart: unless-stopped
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init_postgres.sql:/docker-entrypoint-initdb.d/init.sql
    environment:
      - POSTGRES_DB=lightrag
      - POSTGRES_USER=lightrag
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U lightrag -d lightrag"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag-network

  # ==================== Nginx åå‘ä»£ç†ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰====================
  nginx:
    image: nginx:alpine
    container_name: rag-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./deploy/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./deploy/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - rag-api
    networks:
      - rag-network
    profiles:
      - production

# ==================== æŒä¹…åŒ–å· ====================
volumes:
  redis_data:
    driver: local
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  postgres_data:
    driver: local

# ==================== ç½‘ç»œ ====================
networks:
  rag-network:
    driver: bridge
```

### 1.2 åˆ›å»º PostgreSQL åˆå§‹åŒ–è„šæœ¬

åˆ›å»º `scripts/init_postgres.sql`ï¼š

```sql
-- å¯ç”¨ pgvector æ‰©å±•
CREATE EXTENSION IF NOT EXISTS vector;

-- éªŒè¯æ‰©å±•
SELECT extname, extversion FROM pg_extension WHERE extname = 'vector';

-- åˆ›å»ºç´¢å¼•ï¼ˆåŠ é€Ÿå‘é‡æœç´¢ï¼‰
-- æ³¨æ„ï¼šè¿™äº›è¡¨ç”± LightRAG è‡ªåŠ¨åˆ›å»ºï¼Œæ­¤å¤„ä»…ç”¨äºæ–‡æ¡£è¯´æ˜
-- CREATE INDEX IF NOT EXISTS idx_embeddings_vector ON embeddings USING ivfflat (vector vector_cosine_ops);
```

### 1.3 æ›´æ–° .env é…ç½®

åœ¨ `.env` æ–‡ä»¶ä¸­æ·»åŠ å¤–éƒ¨å­˜å‚¨é…ç½®ï¼š

```bash
# ==================== å¤–éƒ¨å­˜å‚¨é…ç½® ====================

# Redisï¼ˆKV å­˜å‚¨ + ç¼“å­˜ï¼‰
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# Neo4jï¼ˆå›¾å­˜å‚¨ï¼‰
NEO4J_URI=bolt://neo4j:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_secure_password_here  # ä¿®æ”¹ä¸ºå¼ºå¯†ç 

# PostgreSQLï¼ˆå‘é‡å­˜å‚¨ï¼‰
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=lightrag
POSTGRES_USER=lightrag
POSTGRES_PASSWORD=your_secure_password_here  # ä¿®æ”¹ä¸ºå¼ºå¯†ç 

# ==================== LightRAG å­˜å‚¨é…ç½® ====================

# å¯ç”¨å¤–éƒ¨å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
USE_EXTERNAL_STORAGE=true

# KV å­˜å‚¨ç±»å‹ï¼šJsonKVStorageï¼ˆé»˜è®¤ï¼‰æˆ– RedisKVStorage
KV_STORAGE=RedisKVStorage

# å‘é‡å­˜å‚¨ç±»å‹ï¼šNanoVectorDBï¼ˆé»˜è®¤ï¼‰æˆ– PGVectorStorage
VECTOR_STORAGE=PGVectorStorage

# å›¾å­˜å‚¨ç±»å‹ï¼šNetworkXStorageï¼ˆé»˜è®¤ï¼‰æˆ– Neo4JStorage
GRAPH_STORAGE=Neo4JStorage
```

### 1.4 æ›´æ–° src/rag.pyï¼ˆæ”¯æŒå¤–éƒ¨å­˜å‚¨ï¼‰

åœ¨ `src/rag.py` ä¸­æ·»åŠ å¤–éƒ¨å­˜å‚¨æ”¯æŒï¼š

```python
import os
from lightrag import LightRAG

# è¯»å–å¤–éƒ¨å­˜å‚¨é…ç½®
use_external_storage = os.getenv("USE_EXTERNAL_STORAGE", "false").lower() == "true"
kv_storage = os.getenv("KV_STORAGE", "JsonKVStorage")
vector_storage = os.getenv("VECTOR_STORAGE", "NanoVectorDB")
graph_storage = os.getenv("GRAPH_STORAGE", "NetworkXStorage")

# æ ¹æ®é…ç½®åˆ›å»º LightRAG å®ä¾‹
if use_external_storage:
    logger.info("ğŸ”Œ Using external storage backends:")
    logger.info(f"   - KV Storage: {kv_storage}")
    logger.info(f"   - Vector Storage: {vector_storage}")
    logger.info(f"   - Graph Storage: {graph_storage}")

    # å‡†å¤‡å­˜å‚¨é…ç½®
    storage_kwargs = {}

    # Redis KV å­˜å‚¨é…ç½®
    if kv_storage == "RedisKVStorage":
        storage_kwargs["kv_storage"] = "RedisKVStorage"
        storage_kwargs["kv_storage_cls_kwargs"] = {
            "host": os.getenv("REDIS_HOST", "localhost"),
            "port": int(os.getenv("REDIS_PORT", "6379")),
            "db": int(os.getenv("REDIS_DB", "0"))
        }

    # PostgreSQL å‘é‡å­˜å‚¨é…ç½®
    if vector_storage == "PGVectorStorage":
        storage_kwargs["vector_storage"] = "PGVectorStorage"
        storage_kwargs["vector_storage_cls_kwargs"] = {
            "host": os.getenv("POSTGRES_HOST", "localhost"),
            "port": int(os.getenv("POSTGRES_PORT", "5432")),
            "database": os.getenv("POSTGRES_DB", "lightrag"),
            "user": os.getenv("POSTGRES_USER", "lightrag"),
            "password": os.getenv("POSTGRES_PASSWORD", "")
        }

    # Neo4j å›¾å­˜å‚¨é…ç½®
    if graph_storage == "Neo4JStorage":
        storage_kwargs["graph_storage"] = "Neo4JStorage"
        storage_kwargs["graph_storage_cls_kwargs"] = {
            "uri": os.getenv("NEO4J_URI", "bolt://localhost:7687"),
            "user": os.getenv("NEO4J_USERNAME", "neo4j"),
            "password": os.getenv("NEO4J_PASSWORD", "")
        }

    global_lightrag_instance = LightRAG(
        working_dir="./rag_local_storage",  # ä»…ç”¨äºä¸´æ—¶æ–‡ä»¶
        llm_model_func=llm_model_func,
        embedding_func=embedding_func,
        llm_model_max_async=max_async,
        **storage_kwargs  # åº”ç”¨å¤–éƒ¨å­˜å‚¨é…ç½®
    )
else:
    logger.info("ğŸ“ Using local file storage (default)")
    global_lightrag_instance = LightRAG(
        working_dir="./rag_local_storage",
        llm_model_func=llm_model_func,
        embedding_func=embedding_func,
        llm_model_max_async=max_async,
    )
```

### 1.5 éƒ¨ç½²æ­¥éª¤

#### Step 1: ç”Ÿæˆå¯†ç 

```bash
# ç”Ÿæˆå¼ºå¯†ç 
openssl rand -base64 32 > .secrets
NEO4J_PASSWORD=$(head -n 1 .secrets)
POSTGRES_PASSWORD=$(openssl rand -base64 32)

# æ›´æ–° .env æ–‡ä»¶
echo "NEO4J_PASSWORD=$NEO4J_PASSWORD" >> .env
echo "POSTGRES_PASSWORD=$POSTGRES_PASSWORD" >> .env
```

#### Step 2: å¯åŠ¨å¤–éƒ¨å­˜å‚¨æœåŠ¡

```bash
# ä»…å¯åŠ¨æ•°æ®åº“æœåŠ¡ï¼ˆæµ‹è¯•è¿æ¥ï¼‰
docker compose up -d redis neo4j postgres

# ç­‰å¾…å¥åº·æ£€æŸ¥é€šè¿‡
docker compose ps

# æŸ¥çœ‹æ—¥å¿—
docker compose logs redis
docker compose logs neo4j
docker compose logs postgres
```

#### Step 3: éªŒè¯æ•°æ®åº“è¿æ¥

```bash
# æµ‹è¯• Redis
docker compose exec redis redis-cli ping
# é¢„æœŸè¾“å‡º: PONG

# æµ‹è¯• Neo4j
docker compose exec neo4j cypher-shell -u neo4j -p your_password "RETURN 1"
# é¢„æœŸè¾“å‡º: 1

# æµ‹è¯• PostgreSQL
docker compose exec postgres psql -U lightrag -d lightrag -c "SELECT version();"
# é¢„æœŸè¾“å‡º: PostgreSQL 16.x + pgvector
```

#### Step 4: æ•°æ®è¿ç§»ï¼ˆè§ [æ•°æ®è¿ç§»è„šæœ¬](#æ•°æ®è¿ç§»è„šæœ¬)ï¼‰

```bash
# è¿è¡Œè¿ç§»è„šæœ¬
python scripts/migrate_to_external_storage.py --dry-run
python scripts/migrate_to_external_storage.py --execute
```

#### Step 5: å¯åŠ¨åº”ç”¨

```bash
# å¯åŠ¨å®Œæ•´æœåŠ¡
docker compose up -d

# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
docker compose logs -f rag-api

# éªŒè¯å¤–éƒ¨å­˜å‚¨å·²å¯ç”¨
docker compose logs rag-api | grep "external storage"
```

#### Step 6: åŠŸèƒ½éªŒè¯

```bash
# æµ‹è¯•æ–‡æ¡£æ’å…¥
curl -X POST http://localhost:8000/insert \
  -F "doc_id=test_external" \
  -F "file=@test.txt"

# æµ‹è¯•æŸ¥è¯¢
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "æµ‹è¯•æŸ¥è¯¢", "mode": "naive"}'

# æ£€æŸ¥æ•°æ®å·²å­˜å‚¨åˆ°å¤–éƒ¨æ•°æ®åº“
docker compose exec redis redis-cli DBSIZE
docker compose exec neo4j cypher-shell -u neo4j -p your_password "MATCH (n) RETURN count(n)"
docker compose exec postgres psql -U lightrag -d lightrag -c "SELECT COUNT(*) FROM vectors;"
```

### 1.6 ç›‘æ§å’Œè°ƒä¼˜

#### èµ„æºç›‘æ§

```bash
# æŸ¥çœ‹å®¹å™¨èµ„æºå ç”¨
docker stats

# æŸ¥çœ‹æ•°æ®åº“å¤§å°
docker compose exec postgres psql -U lightrag -d lightrag -c "
SELECT pg_size_pretty(pg_database_size('lightrag'));
"

docker compose exec neo4j cypher-shell -u neo4j -p your_password "
CALL dbms.queryJmx('org.neo4j:instance=kernel#0,name=Store file sizes')
YIELD attributes
RETURN attributes.TotalStoreSize.value;
"
```

#### æ€§èƒ½è°ƒä¼˜

**Redis è°ƒä¼˜**ï¼š
```bash
# ç¼–è¾‘ docker-compose.ymlï¼Œè°ƒæ•´ Redis å†…å­˜é™åˆ¶
command: >
  redis-server
  --appendonly yes
  --maxmemory 1gb           # å¢åŠ å†…å­˜é™åˆ¶
  --maxmemory-policy allkeys-lru
```

**Neo4j è°ƒä¼˜**ï¼š
```yaml
environment:
  - NEO4J_server_memory_heap_max__size=2G  # å¢åŠ å †å†…å­˜
  - NEO4J_server_memory_pagecache_size=1G  # å¢åŠ é¡µç¼“å­˜
```

**PostgreSQL è°ƒä¼˜**ï¼š
```bash
# ç¼–è¾‘ postgresql.confï¼ˆé€šè¿‡å·æŒ‚è½½ï¼‰
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 16MB
```

---

## é˜¶æ®µ 2ï¼šAWS æ‰˜ç®¡æœåŠ¡è¿ç§»

**æ—¶é—´**: 2-3 å‘¨
**ç›®æ ‡**: è¿ç§»åˆ° AWS æ‰˜ç®¡æœåŠ¡ï¼ˆElastiCache + Aurora Serverless + Neo4j Auraï¼‰
**ç¯å¢ƒ**: EC2 + AWS æ‰˜ç®¡æ•°æ®åº“

### 2.1 AWS èµ„æºåˆ›å»º

#### åˆ›å»º Aurora Serverless v2 é›†ç¾¤

```bash
# ä½¿ç”¨ AWS CLI åˆ›å»º Aurora é›†ç¾¤
aws rds create-db-cluster \
  --db-cluster-identifier lightrag-aurora \
  --engine aurora-postgresql \
  --engine-version 16.1 \
  --master-username lightrag \
  --master-user-password your_secure_password \
  --database-name lightrag \
  --serverless-v2-scaling-configuration MinCapacity=0.5,MaxCapacity=16 \
  --enable-http-endpoint \
  --vpc-security-group-ids sg-xxxxxx \
  --db-subnet-group-name your-subnet-group

# åˆ›å»ºå®ä¾‹ï¼ˆServerless v2 éœ€è¦å®ä¾‹ï¼‰
aws rds create-db-instance \
  --db-instance-identifier lightrag-aurora-instance-1 \
  --db-cluster-identifier lightrag-aurora \
  --db-instance-class db.serverless \
  --engine aurora-postgresql

# å®‰è£… pgvector æ‰©å±•
psql -h lightrag-aurora.cluster-xxxxxx.us-east-1.rds.amazonaws.com \
     -U lightrag \
     -d lightrag \
     -c "CREATE EXTENSION vector;"
```

#### åˆ›å»º ElastiCache Redis é›†ç¾¤

```bash
# åˆ›å»º Redis é›†ç¾¤ï¼ˆServerless æ¨¡å¼ï¼‰
aws elasticache create-serverless-cache \
  --serverless-cache-name lightrag-redis \
  --engine redis \
  --serverless-cache-usage-limits DataStorage={Maximum=1,Unit=GB} \
  --security-group-ids sg-xxxxxx \
  --subnet-ids subnet-xxxxxx subnet-yyyyyy
```

#### æ³¨å†Œ Neo4j Auraï¼ˆæ‰˜ç®¡å›¾æ•°æ®åº“ï¼‰

```bash
# è®¿é—® https://console.neo4j.io/ åˆ›å»ºå®ä¾‹
# é€‰æ‹©ï¼šProfessionalï¼ˆ$65/æœˆï¼‰æˆ– Enterpriseï¼ˆ$200/æœˆï¼‰
# è®°å½•è¿æ¥ä¿¡æ¯ï¼š
# - URI: neo4j+s://xxxxx.databases.neo4j.io
# - Username: neo4j
# - Password: generated_password
```

### 2.2 æ›´æ–° .env é…ç½®ï¼ˆAWS æ‰˜ç®¡æœåŠ¡ï¼‰

```bash
# ==================== AWS æ‰˜ç®¡æœåŠ¡é…ç½® ====================

# ElastiCache Redis
REDIS_HOST=lightrag-redis.xxxxxx.cache.amazonaws.com
REDIS_PORT=6379
REDIS_SSL=true  # ElastiCache å»ºè®®å¯ç”¨ SSL

# Aurora Serverless PostgreSQL
POSTGRES_HOST=lightrag-aurora.cluster-xxxxxx.us-east-1.rds.amazonaws.com
POSTGRES_PORT=5432
POSTGRES_DB=lightrag
POSTGRES_USER=lightrag
POSTGRES_PASSWORD=your_aurora_password
POSTGRES_SSLMODE=require  # Aurora å¼ºåˆ¶ SSL

# Neo4j Aura
NEO4J_URI=neo4j+s://xxxxx.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_aura_password
NEO4J_DATABASE=neo4j  # Aura é»˜è®¤æ•°æ®åº“å

# å¯ç”¨å¤–éƒ¨å­˜å‚¨
USE_EXTERNAL_STORAGE=true
KV_STORAGE=RedisKVStorage
VECTOR_STORAGE=PGVectorStorage
GRAPH_STORAGE=Neo4JStorage
```

### 2.3 æ•°æ®è¿ç§»ï¼ˆDocker Compose â†’ AWSï¼‰

```bash
# Step 1: å¤‡ä»½ Docker Compose æ•°æ®
docker compose exec redis redis-cli --rdb /data/dump.rdb
docker compose exec postgres pg_dump -U lightrag lightrag > backup_postgres.sql
docker compose exec neo4j neo4j-admin database dump neo4j --to-path=/tmp/neo4j-backup

# Step 2: æ¢å¤åˆ° AWS æœåŠ¡
# Redis: ä½¿ç”¨ redis-cli --rdb å¯¼å…¥
cat backup_redis.rdb | redis-cli -h lightrag-redis.xxxxxx.cache.amazonaws.com --pipe

# PostgreSQL: ä½¿ç”¨ psql å¯¼å…¥
psql -h lightrag-aurora.cluster-xxxxxx.us-east-1.rds.amazonaws.com \
     -U lightrag -d lightrag < backup_postgres.sql

# Neo4j: ä½¿ç”¨ Neo4j Aura æ§åˆ¶å°å¯¼å…¥
# è®¿é—®æ§åˆ¶å° â†’ Import â†’ ä¸Šä¼  dump æ–‡ä»¶
```

### 2.4 æ›´æ–° docker-compose.ymlï¼ˆç§»é™¤æœ¬åœ°æ•°æ®åº“ï¼‰

```yaml
version: '3.8'

services:
  # ä»…ä¿ç•™åº”ç”¨æœåŠ¡ï¼Œç§»é™¤ Redis/Neo4j/PostgreSQL
  rag-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rag-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    env_file:
      - .env
    volumes:
      - ./output:/app/output
      - ./logs:/app/logs
    environment:
      - TZ=Asia/Shanghai
      - PYTHONUNBUFFERED=1
      # AWS æ‰˜ç®¡æœåŠ¡é…ç½®ï¼ˆä» .env è¯»å–ï¼‰
    networks:
      - rag-network

  nginx:
    image: nginx:alpine
    container_name: rag-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./deploy/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./deploy/ssl:/etc/nginx/ssl:ro
    depends_on:
      - rag-api
    networks:
      - rag-network

networks:
  rag-network:
    driver: bridge
```

### 2.5 æˆæœ¬ä¼°ç®—ï¼ˆAWS æ‰˜ç®¡æœåŠ¡ï¼‰

| æœåŠ¡ | ç±»å‹ | é…ç½® | æœˆæˆæœ¬ |
|------|------|------|--------|
| **Aurora Serverless v2** | PostgreSQL | 0.5-16 ACU | $40-500 |
| **ElastiCache Serverless** | Redis | 1GB æ•°æ® | $40-80 |
| **Neo4j Aura** | Professional | 8GB å­˜å‚¨ | $65 |
| **EC2** | t3.small | åº”ç”¨å®¹å™¨ | $10-15 |
| **æ•°æ®ä¼ è¾“** | å‡ºç«™æµé‡ | ~100GB | $10 |
| **åˆè®¡** | - | - | **$165-670/æœˆ** |

---

## é˜¶æ®µ 3ï¼šè¿ç§»åˆ° AWS ECS

**æ—¶é—´**: 3-4 å‘¨
**ç›®æ ‡**: æ— çŠ¶æ€å®¹å™¨åŒ–éƒ¨ç½²ï¼Œæ”¯æŒè‡ªåŠ¨æ‰©ç¼©å®¹
**ç¯å¢ƒ**: AWS ECS Fargate + ALB + æ‰˜ç®¡æ•°æ®åº“

### 3.1 æ¶æ„è®¾è®¡

```
Internet
    â†“
Route 53 (DNS)
    â†“
CloudFront (CDNï¼Œå¯é€‰)
    â†“
Application Load Balancer (ALB)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ECS Service                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Task 1  â”‚  â”‚ Task 2  â”‚  â”‚ Task 3  â”‚ â”‚ â† è‡ªåŠ¨æ‰©ç¼©å®¹ï¼ˆ2-10 ä¸ªä»»åŠ¡ï¼‰
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“              â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VPC (Private Subnet)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ElastiCacheâ”‚ â”‚Aurora  â”‚  â”‚Neo4j Auraâ”‚  â”‚
â”‚  â”‚  Redis   â”‚  â”‚Postgresâ”‚  â”‚ (å¤–éƒ¨)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 åˆ›å»º ECR ä»“åº“

```bash
# åˆ›å»º ECR ä»“åº“
aws ecr create-repository --repository-name rag-api

# ç™»å½• ECR
aws ecr get-login-password --region us-east-1 | \
  docker login --username AWS --password-stdin \
  123456789012.dkr.ecr.us-east-1.amazonaws.com

# æ„å»ºå¹¶æ¨é€é•œåƒ
docker build -t rag-api:latest .
docker tag rag-api:latest 123456789012.dkr.ecr.us-east-1.amazonaws.com/rag-api:latest
docker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/rag-api:latest
```

### 3.3 åˆ›å»º ECS ä»»åŠ¡å®šä¹‰

åˆ›å»º `ecs-task-definition.json`ï¼š

```json
{
  "family": "rag-api",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "1024",
  "memory": "2048",
  "executionRoleArn": "arn:aws:iam::123456789012:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::123456789012:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "rag-api",
      "image": "123456789012.dkr.ecr.us-east-1.amazonaws.com/rag-api:latest",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {"name": "TZ", "value": "Asia/Shanghai"},
        {"name": "PYTHONUNBUFFERED", "value": "1"},
        {"name": "USE_EXTERNAL_STORAGE", "value": "true"}
      ],
      "secrets": [
        {
          "name": "ARK_API_KEY",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:123456789012:secret:rag-api/ark-api-key"
        },
        {
          "name": "REDIS_HOST",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:123456789012:secret:rag-api/redis-host"
        },
        {
          "name": "POSTGRES_PASSWORD",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:123456789012:secret:rag-api/postgres-password"
        },
        {
          "name": "NEO4J_PASSWORD",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:123456789012:secret:rag-api/neo4j-password"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/rag-api",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:8000/ || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3,
        "startPeriod": 60
      }
    }
  ]
}
```

æ³¨å†Œä»»åŠ¡å®šä¹‰ï¼š

```bash
aws ecs register-task-definition --cli-input-json file://ecs-task-definition.json
```

### 3.4 åˆ›å»º Secrets Manager å¯†é’¥

```bash
# åˆ›å»ºå¯†é’¥
aws secretsmanager create-secret \
  --name rag-api/ark-api-key \
  --secret-string "your_ark_api_key"

aws secretsmanager create-secret \
  --name rag-api/redis-host \
  --secret-string "lightrag-redis.xxxxxx.cache.amazonaws.com"

aws secretsmanager create-secret \
  --name rag-api/postgres-password \
  --secret-string "your_postgres_password"

aws secretsmanager create-secret \
  --name rag-api/neo4j-password \
  --secret-string "your_neo4j_password"
```

### 3.5 åˆ›å»º Application Load Balancer

```bash
# åˆ›å»º ALB
aws elbv2 create-load-balancer \
  --name rag-api-alb \
  --subnets subnet-xxxxxx subnet-yyyyyy \
  --security-groups sg-xxxxxx \
  --scheme internet-facing

# åˆ›å»ºç›®æ ‡ç»„
aws elbv2 create-target-group \
  --name rag-api-tg \
  --protocol HTTP \
  --port 8000 \
  --vpc-id vpc-xxxxxx \
  --target-type ip \
  --health-check-path / \
  --health-check-interval-seconds 30

# åˆ›å»ºç›‘å¬å™¨
aws elbv2 create-listener \
  --load-balancer-arn arn:aws:elasticloadbalancing:us-east-1:123456789012:loadbalancer/app/rag-api-alb/xxxxx \
  --protocol HTTP \
  --port 80 \
  --default-actions Type=forward,TargetGroupArn=arn:aws:elasticloadbalancing:us-east-1:123456789012:targetgroup/rag-api-tg/xxxxx
```

### 3.6 åˆ›å»º ECS æœåŠ¡

```bash
# åˆ›å»º ECS é›†ç¾¤
aws ecs create-cluster --cluster-name rag-api-cluster

# åˆ›å»º ECS æœåŠ¡ï¼ˆå¸¦è‡ªåŠ¨æ‰©ç¼©å®¹ï¼‰
aws ecs create-service \
  --cluster rag-api-cluster \
  --service-name rag-api-service \
  --task-definition rag-api:1 \
  --desired-count 2 \
  --launch-type FARGATE \
  --platform-version LATEST \
  --network-configuration "awsvpcConfiguration={subnets=[subnet-xxxxxx,subnet-yyyyyy],securityGroups=[sg-xxxxxx],assignPublicIp=DISABLED}" \
  --load-balancers "targetGroupArn=arn:aws:elasticloadbalancing:us-east-1:123456789012:targetgroup/rag-api-tg/xxxxx,containerName=rag-api,containerPort=8000" \
  --health-check-grace-period-seconds 60
```

### 3.7 é…ç½®è‡ªåŠ¨æ‰©ç¼©å®¹

```bash
# æ³¨å†Œå¯æ‰©å±•ç›®æ ‡
aws application-autoscaling register-scalable-target \
  --service-namespace ecs \
  --resource-id service/rag-api-cluster/rag-api-service \
  --scalable-dimension ecs:service:DesiredCount \
  --min-capacity 2 \
  --max-capacity 10

# åˆ›å»º CPU ä½¿ç”¨ç‡æ‰©ç¼©å®¹ç­–ç•¥
aws application-autoscaling put-scaling-policy \
  --service-namespace ecs \
  --resource-id service/rag-api-cluster/rag-api-service \
  --scalable-dimension ecs:service:DesiredCount \
  --policy-name cpu-scaling-policy \
  --policy-type TargetTrackingScaling \
  --target-tracking-scaling-policy-configuration '{
    "TargetValue": 70.0,
    "PredefinedMetricSpecification": {
      "PredefinedMetricType": "ECSServiceAverageCPUUtilization"
    },
    "ScaleInCooldown": 300,
    "ScaleOutCooldown": 60
  }'

# åˆ›å»ºå†…å­˜ä½¿ç”¨ç‡æ‰©ç¼©å®¹ç­–ç•¥
aws application-autoscaling put-scaling-policy \
  --service-namespace ecs \
  --resource-id service/rag-api-cluster/rag-api-service \
  --scalable-dimension ecs:service:DesiredCount \
  --policy-name memory-scaling-policy \
  --policy-type TargetTrackingScaling \
  --target-tracking-scaling-policy-configuration '{
    "TargetValue": 80.0,
    "PredefinedMetricSpecification": {
      "PredefinedMetricType": "ECSServiceAverageMemoryUtilization"
    },
    "ScaleInCooldown": 300,
    "ScaleOutCooldown": 60
  }'
```

### 3.8 CI/CD é›†æˆï¼ˆGitHub Actionsï¼‰

åˆ›å»º `.github/workflows/deploy-ecs.yml`ï¼š

```yaml
name: Deploy to ECS

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build, tag, and push image to Amazon ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: rag-api
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest

      - name: Update ECS service
        run: |
          aws ecs update-service \
            --cluster rag-api-cluster \
            --service rag-api-service \
            --force-new-deployment
```

### 3.9 æˆæœ¬ä¼°ç®—ï¼ˆAWS ECS éƒ¨ç½²ï¼‰

| æœåŠ¡ | ç±»å‹ | é…ç½® | æœˆæˆæœ¬ |
|------|------|------|--------|
| **ECS Fargate** | è®¡ç®—èµ„æº | 2-10 ä»»åŠ¡ï¼ˆ1 vCPU, 2GBï¼‰ | $60-300 |
| **ALB** | è´Ÿè½½å‡è¡¡å™¨ | æ ‡å‡†é…ç½® | $20 |
| **Aurora Serverless v2** | PostgreSQL | 0.5-16 ACU | $40-500 |
| **ElastiCache Serverless** | Redis | 1GB æ•°æ® | $40-80 |
| **Neo4j Aura** | Professional | 8GB å­˜å‚¨ | $65 |
| **CloudWatch Logs** | æ—¥å¿—å­˜å‚¨ | 10GB/æœˆ | $5 |
| **æ•°æ®ä¼ è¾“** | å‡ºç«™æµé‡ | ~200GB | $20 |
| **åˆè®¡** | - | - | **$250-990/æœˆ** |

---

## æ•°æ®è¿ç§»è„šæœ¬

åˆ›å»º `scripts/migrate_to_external_storage.py`ï¼š

```python
#!/usr/bin/env python3
"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šæ–‡ä»¶å­˜å‚¨ â†’ å¤–éƒ¨æ•°æ®åº“

ä½¿ç”¨æ–¹æ³•:
  python scripts/migrate_to_external_storage.py --dry-run    # é¢„æ¼”
  python scripts/migrate_to_external_storage.py --execute    # æ‰§è¡Œ
"""

import os
import json
import asyncio
import argparse
from pathlib import Path
from typing import Dict, List

# å¯¼å…¥ LightRAG å­˜å‚¨åç«¯
from lightrag.kg.redis_impl import RedisKVStorage
from lightrag.kg.postgres_impl import PGVectorStorage
from lightrag.kg.neo4j_impl import Neo4JStorage


class DataMigrator:
    def __init__(self, source_dir: str, dry_run: bool = True):
        self.source_dir = Path(source_dir)
        self.dry_run = dry_run
        self.stats = {
            "kv_entries": 0,
            "vectors": 0,
            "graph_nodes": 0,
            "graph_edges": 0
        }

    async def migrate_kv_storage(self):
        """è¿ç§» KV å­˜å‚¨ï¼šJSON â†’ Redis"""
        print("\nğŸ”„ Migrating KV storage (JSON â†’ Redis)...")

        # è¯»å–æºæ–‡ä»¶
        kv_files = [
            "kv_store_full_docs.json",
            "kv_store_full_entities.json",
            "kv_store_full_relations.json",
            "kv_store_text_chunks.json",
        ]

        if self.dry_run:
            for file in kv_files:
                file_path = self.source_dir / file
                if file_path.exists():
                    with open(file_path) as f:
                        data = json.load(f)
                        self.stats["kv_entries"] += len(data)
                        print(f"  âœ“ Found {len(data)} entries in {file}")
        else:
            # å®é™…è¿ç§»
            redis = RedisKVStorage(
                namespace="lightrag",
                global_config={},
                embedding_func=None,
                host=os.getenv("REDIS_HOST"),
                port=int(os.getenv("REDIS_PORT", "6379"))
            )

            for file in kv_files:
                file_path = self.source_dir / file
                if file_path.exists():
                    with open(file_path) as f:
                        data = json.load(f)
                        for key, value in data.items():
                            await redis.set(key, value)
                        self.stats["kv_entries"] += len(data)
                        print(f"  âœ“ Migrated {len(data)} entries from {file}")

    async def migrate_vector_storage(self):
        """è¿ç§»å‘é‡å­˜å‚¨ï¼šNanoVectorDB â†’ PostgreSQL"""
        print("\nğŸ”„ Migrating vector storage (JSON â†’ PostgreSQL)...")

        vector_files = [
            "vdb_entities.json",
            "vdb_relationships.json",
            "vdb_chunks.json"
        ]

        if self.dry_run:
            for file in vector_files:
                file_path = self.source_dir / file
                if file_path.exists():
                    with open(file_path) as f:
                        data = json.load(f)
                        self.stats["vectors"] += len(data)
                        print(f"  âœ“ Found {len(data)} vectors in {file}")
        else:
            # å®é™…è¿ç§»
            pg_vector = PGVectorStorage(
                namespace="lightrag",
                global_config={},
                embedding_func=None,
                host=os.getenv("POSTGRES_HOST"),
                port=int(os.getenv("POSTGRES_PORT", "5432")),
                database=os.getenv("POSTGRES_DB"),
                user=os.getenv("POSTGRES_USER"),
                password=os.getenv("POSTGRES_PASSWORD")
            )

            await pg_vector.initialize()

            for file in vector_files:
                file_path = self.source_dir / file
                if file_path.exists():
                    with open(file_path) as f:
                        data = json.load(f)
                        for key, item in data.items():
                            await pg_vector.insert(
                                id=key,
                                embedding=item["embedding"],
                                metadata=item.get("metadata", {})
                            )
                        self.stats["vectors"] += len(data)
                        print(f"  âœ“ Migrated {len(data)} vectors from {file}")

    async def migrate_graph_storage(self):
        """è¿ç§»å›¾å­˜å‚¨ï¼šNetworkX/GraphML â†’ Neo4j"""
        print("\nğŸ”„ Migrating graph storage (GraphML â†’ Neo4j)...")

        graph_file = self.source_dir / "graph_chunk_entity_relation.graphml"

        if not graph_file.exists():
            print("  âš ï¸  GraphML file not found, skipping graph migration")
            return

        if self.dry_run:
            import networkx as nx
            G = nx.read_graphml(graph_file)
            self.stats["graph_nodes"] = G.number_of_nodes()
            self.stats["graph_edges"] = G.number_of_edges()
            print(f"  âœ“ Found {self.stats['graph_nodes']} nodes and {self.stats['graph_edges']} edges")
        else:
            # å®é™…è¿ç§»
            import networkx as nx
            from neo4j import AsyncGraphDatabase

            G = nx.read_graphml(graph_file)

            driver = AsyncGraphDatabase.driver(
                os.getenv("NEO4J_URI"),
                auth=(os.getenv("NEO4J_USERNAME"), os.getenv("NEO4J_PASSWORD"))
            )

            async with driver.session() as session:
                # åˆ›å»ºèŠ‚ç‚¹
                for node_id, node_data in G.nodes(data=True):
                    await session.run(
                        "MERGE (n:Entity {id: $id}) SET n += $properties",
                        id=node_id,
                        properties=node_data
                    )
                self.stats["graph_nodes"] = G.number_of_nodes()

                # åˆ›å»ºè¾¹
                for src, tgt, edge_data in G.edges(data=True):
                    await session.run(
                        "MATCH (a:Entity {id: $src}), (b:Entity {id: $tgt}) "
                        "MERGE (a)-[r:RELATES_TO]->(b) SET r += $properties",
                        src=src,
                        tgt=tgt,
                        properties=edge_data
                    )
                self.stats["graph_edges"] = G.number_of_edges()

            await driver.close()
            print(f"  âœ“ Migrated {self.stats['graph_nodes']} nodes and {self.stats['graph_edges']} edges")

    async def run(self):
        """æ‰§è¡Œå®Œæ•´è¿ç§»"""
        print("=" * 70)
        print(f"{'DRY RUN MODE' if self.dry_run else 'LIVE MIGRATION MODE'}")
        print("=" * 70)

        await self.migrate_kv_storage()
        await self.migrate_vector_storage()
        await self.migrate_graph_storage()

        print("\n" + "=" * 70)
        print("ğŸ“Š Migration Summary")
        print("=" * 70)
        print(f"  KV Entries:   {self.stats['kv_entries']}")
        print(f"  Vectors:      {self.stats['vectors']}")
        print(f"  Graph Nodes:  {self.stats['graph_nodes']}")
        print(f"  Graph Edges:  {self.stats['graph_edges']}")
        print("=" * 70)

        if self.dry_run:
            print("\nâœ… Dry run completed. Run with --execute to perform actual migration.")
        else:
            print("\nâœ… Migration completed successfully!")


async def main():
    parser = argparse.ArgumentParser(description="Migrate LightRAG data to external storage")
    parser.add_argument("--dry-run", action="store_true", help="Simulate migration without writing data")
    parser.add_argument("--execute", action="store_true", help="Execute actual migration")
    parser.add_argument("--source-dir", default="./rag_local_storage", help="Source directory for file storage")

    args = parser.parse_args()

    if not args.dry_run and not args.execute:
        print("âŒ Error: Must specify either --dry-run or --execute")
        return

    migrator = DataMigrator(
        source_dir=args.source_dir,
        dry_run=args.dry_run
    )

    await migrator.run()


if __name__ == "__main__":
    asyncio.run(main())
```

---

## å›æ»šæ–¹æ¡ˆ

### é˜¶æ®µ 1 å›æ»šï¼ˆå¤–éƒ¨å­˜å‚¨ â†’ æ–‡ä»¶å­˜å‚¨ï¼‰

```bash
# Step 1: å¤‡ä»½å¤–éƒ¨æ•°æ®åº“
docker compose exec redis redis-cli SAVE
docker compose exec postgres pg_dump -U lightrag lightrag > backup.sql
docker compose exec neo4j neo4j-admin database dump neo4j --to-path=/tmp/backup

# Step 2: åœæ­¢æœåŠ¡
docker compose down

# Step 3: æ¢å¤ docker-compose.yml åˆ°æ–‡ä»¶å­˜å‚¨ç‰ˆæœ¬
git checkout HEAD~1 docker-compose.yml

# Step 4: æ›´æ–° .env
USE_EXTERNAL_STORAGE=false

# Step 5: å¯åŠ¨æœåŠ¡
docker compose up -d
```

### é˜¶æ®µ 2 å›æ»šï¼ˆAWS æ‰˜ç®¡ â†’ Docker Composeï¼‰

```bash
# Step 1: ä» AWS å¯¼å‡ºæ•°æ®
aws elasticache create-snapshot \
  --snapshot-name lightrag-backup-$(date +%Y%m%d)

aws rds create-db-snapshot \
  --db-snapshot-identifier lightrag-backup-$(date +%Y%m%d)

# Step 2: å¯åŠ¨æœ¬åœ° Docker Compose æ•°æ®åº“
docker compose up -d redis neo4j postgres

# Step 3: æ¢å¤æ•°æ®ï¼ˆä½¿ç”¨å¤‡ä»½è„šæœ¬ï¼‰
python scripts/restore_from_aws.py

# Step 4: æ›´æ–° .env æŒ‡å‘æœ¬åœ°æœåŠ¡
REDIS_HOST=localhost
POSTGRES_HOST=localhost
NEO4J_URI=bolt://localhost:7687
```

### é˜¶æ®µ 3 å›æ»šï¼ˆECS â†’ EC2ï¼‰

```bash
# Step 1: åœæ­¢ ECS æœåŠ¡
aws ecs update-service \
  --cluster rag-api-cluster \
  --service rag-api-service \
  --desired-count 0

# Step 2: åœ¨ EC2 ä¸Šå¯åŠ¨ Docker Compose
ssh ec2-user@your-ec2-instance
cd /app/rag-api
docker compose up -d

# Step 3: æ›´æ–° DNSï¼ˆæŒ‡å‘ EC2 IPï¼‰
aws route53 change-resource-record-sets \
  --hosted-zone-id Z123456 \
  --change-batch file://update-dns-to-ec2.json
```

---

## ç›‘æ§å’ŒéªŒè¯

### CloudWatch ç›‘æ§æŒ‡æ ‡

```bash
# ECS ä»»åŠ¡ CPU ä½¿ç”¨ç‡
aws cloudwatch get-metric-statistics \
  --namespace AWS/ECS \
  --metric-name CPUUtilization \
  --dimensions Name=ServiceName,Value=rag-api-service \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 300 \
  --statistics Average

# Aurora æ•°æ®åº“è¿æ¥æ•°
aws cloudwatch get-metric-statistics \
  --namespace AWS/RDS \
  --metric-name DatabaseConnections \
  --dimensions Name=DBClusterIdentifier,Value=lightrag-aurora \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 300 \
  --statistics Average
```

### å¥åº·æ£€æŸ¥è„šæœ¬

åˆ›å»º `scripts/health_check.sh`ï¼š

```bash
#!/bin/bash

echo "ğŸ¥ RAG API Health Check"
echo "========================"

# æ£€æŸ¥ API å¥åº·çŠ¶æ€
API_URL=${API_URL:-"http://localhost:8000"}
echo -n "API Health: "
curl -sf $API_URL/ > /dev/null && echo "âœ… OK" || echo "âŒ FAIL"

# æ£€æŸ¥ Redis è¿æ¥
echo -n "Redis: "
redis-cli -h ${REDIS_HOST:-localhost} ping > /dev/null 2>&1 && echo "âœ… OK" || echo "âŒ FAIL"

# æ£€æŸ¥ PostgreSQL è¿æ¥
echo -n "PostgreSQL: "
pg_isready -h ${POSTGRES_HOST:-localhost} -U lightrag > /dev/null 2>&1 && echo "âœ… OK" || echo "âŒ FAIL"

# æ£€æŸ¥ Neo4j è¿æ¥
echo -n "Neo4j: "
cypher-shell -a ${NEO4J_URI:-bolt://localhost:7687} \
  -u ${NEO4J_USERNAME:-neo4j} \
  -p ${NEO4J_PASSWORD} \
  "RETURN 1" > /dev/null 2>&1 && echo "âœ… OK" || echo "âŒ FAIL"

# æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½
echo -n "Query Test: "
RESPONSE=$(curl -sf -X POST $API_URL/query \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "mode": "naive"}')

if [ -n "$RESPONSE" ]; then
  echo "âœ… OK"
else
  echo "âŒ FAIL"
fi
```

---

## é™„å½•

### A. Terraform åŸºç¡€è®¾æ–½ä»£ç ç¤ºä¾‹

åˆ›å»º `terraform/main.tf`ï¼š

```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = "us-east-1"
}

# VPC å’Œå­ç½‘
module "vpc" {
  source = "terraform-aws-modules/vpc/aws"

  name = "rag-api-vpc"
  cidr = "10.0.0.0/16"

  azs             = ["us-east-1a", "us-east-1b"]
  private_subnets = ["10.0.1.0/24", "10.0.2.0/24"]
  public_subnets  = ["10.0.101.0/24", "10.0.102.0/24"]

  enable_nat_gateway = true
  single_nat_gateway = true
}

# ElastiCache Redis
resource "aws_elasticache_serverless_cache" "redis" {
  engine = "redis"
  name   = "lightrag-redis"

  cache_usage_limits {
    data_storage {
      maximum = 1
      unit    = "GB"
    }
  }

  security_group_ids = [aws_security_group.redis.id]
  subnet_ids         = module.vpc.private_subnets
}

# Aurora Serverless v2
resource "aws_rds_cluster" "aurora" {
  cluster_identifier     = "lightrag-aurora"
  engine                 = "aurora-postgresql"
  engine_version         = "16.1"
  database_name          = "lightrag"
  master_username        = "lightrag"
  master_password        = var.postgres_password

  serverlessv2_scaling_configuration {
    min_capacity = 0.5
    max_capacity = 16
  }

  vpc_security_group_ids = [aws_security_group.aurora.id]
  db_subnet_group_name   = aws_db_subnet_group.aurora.name
}

resource "aws_rds_cluster_instance" "aurora_instance" {
  identifier         = "lightrag-aurora-instance-1"
  cluster_identifier = aws_rds_cluster.aurora.id
  instance_class     = "db.serverless"
  engine             = aws_rds_cluster.aurora.engine
}

# ECS é›†ç¾¤
resource "aws_ecs_cluster" "main" {
  name = "rag-api-cluster"
}

# ECS ä»»åŠ¡å®šä¹‰
resource "aws_ecs_task_definition" "rag_api" {
  family                   = "rag-api"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  cpu                      = "1024"
  memory                   = "2048"
  execution_role_arn       = aws_iam_role.ecs_execution_role.arn

  container_definitions = jsonencode([
    {
      name  = "rag-api"
      image = "${aws_ecr_repository.rag_api.repository_url}:latest"
      portMappings = [
        {
          containerPort = 8000
          protocol      = "tcp"
        }
      ]
      environment = [
        {name = "USE_EXTERNAL_STORAGE", value = "true"},
        {name = "REDIS_HOST", value = aws_elasticache_serverless_cache.redis.endpoint[0].address}
      ]
    }
  ])
}

# ECS æœåŠ¡
resource "aws_ecs_service" "rag_api" {
  name            = "rag-api-service"
  cluster         = aws_ecs_cluster.main.id
  task_definition = aws_ecs_task_definition.rag_api.arn
  desired_count   = 2
  launch_type     = "FARGATE"

  network_configuration {
    subnets          = module.vpc.private_subnets
    security_groups  = [aws_security_group.rag_api.id]
    assign_public_ip = false
  }

  load_balancer {
    target_group_arn = aws_lb_target_group.rag_api.arn
    container_name   = "rag-api"
    container_port   = 8000
  }
}

# Application Load Balancer
resource "aws_lb" "main" {
  name               = "rag-api-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = module.vpc.public_subnets
}

resource "aws_lb_target_group" "rag_api" {
  name        = "rag-api-tg"
  port        = 8000
  protocol    = "HTTP"
  vpc_id      = module.vpc.vpc_id
  target_type = "ip"

  health_check {
    path                = "/"
    healthy_threshold   = 2
    unhealthy_threshold = 10
  }
}

resource "aws_lb_listener" "http" {
  load_balancer_arn = aws_lb.main.arn
  port              = "80"
  protocol          = "HTTP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.rag_api.arn
  }
}
```

### B. æˆæœ¬ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨ Savings Plans**ï¼šæ‰¿è¯º 1 å¹´ä½¿ç”¨ï¼ŒèŠ‚çœ 30-50%
2. **Aurora Serverless v2 æš‚åœç­–ç•¥**ï¼šè®¾ç½® `min_capacity=0.5` é¿å…å®Œå…¨æš‚åœ
3. **ElastiCache æ•°æ®åˆ†å±‚**ï¼šä½¿ç”¨ Serverless æ¨¡å¼ï¼ŒæŒ‰éœ€ä»˜è´¹
4. **ECS Spot å®ä¾‹**ï¼šéå…³é”®ä»»åŠ¡ä½¿ç”¨ Spotï¼ŒèŠ‚çœ 70%
5. **CloudFront CDN**ï¼šé™æ€èµ„æºä½¿ç”¨ CDNï¼Œå‡å°‘æ•°æ®ä¼ è¾“æˆæœ¬

### C. å®‰å…¨æ£€æŸ¥æ¸…å•

- [ ] æ‰€æœ‰å¯†ç ä½¿ç”¨ AWS Secrets Manager ç®¡ç†
- [ ] æ•°æ®åº“è¿æ¥å¼ºåˆ¶ SSL/TLS
- [ ] ECS ä»»åŠ¡ä½¿ç”¨ç§æœ‰å­ç½‘ï¼Œé€šè¿‡ NAT ç½‘å…³è®¿é—®å¤–ç½‘
- [ ] å®‰å…¨ç»„é™åˆ¶å…¥ç«™æµé‡ï¼ˆALB â†’ ECS â†’ æ•°æ®åº“ï¼‰
- [ ] å¯ç”¨ CloudTrail å®¡è®¡æ—¥å¿—
- [ ] é…ç½® AWS WAF é˜²æ­¢å¸¸è§æ”»å‡»
- [ ] å¯ç”¨ GuardDuty å¨èƒæ£€æµ‹

---

## æ€»ç»“

æœ¬æŒ‡å—æä¾›äº†ä»æ–‡ä»¶å­˜å‚¨åˆ° AWS ECS éƒ¨ç½²çš„å®Œæ•´è¿ç§»è·¯å¾„ï¼Œåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š

1. **é˜¶æ®µ 1ï¼ˆ1-2 å‘¨ï¼‰**ï¼šDocker Compose å¤–éƒ¨åŒ–å­˜å‚¨ï¼ˆæœ¬åœ°æµ‹è¯•ï¼‰
2. **é˜¶æ®µ 2ï¼ˆ2-3 å‘¨ï¼‰**ï¼šAWS æ‰˜ç®¡æœåŠ¡è¿ç§»ï¼ˆé«˜å¯ç”¨ï¼‰
3. **é˜¶æ®µ 3ï¼ˆ3-4 å‘¨ï¼‰**ï¼šECS Fargate éƒ¨ç½²ï¼ˆæ— çŠ¶æ€ã€è‡ªåŠ¨æ‰©ç¼©å®¹ï¼‰

æ¯ä¸ªé˜¶æ®µéƒ½æœ‰è¯¦ç»†çš„æ­¥éª¤ã€é…ç½®ç¤ºä¾‹ã€æ•°æ®è¿ç§»è„šæœ¬å’Œå›æ»šæ–¹æ¡ˆï¼Œç¡®ä¿å®‰å…¨ã€å¯æ§çš„ç”Ÿäº§ç¯å¢ƒè¿ç§»ã€‚

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**ï¼š
1. åœ¨ dev åˆ†æ”¯ä¿æŒæ–‡ä»¶å­˜å‚¨ï¼ˆå¿«é€Ÿå¼€å‘ï¼‰
2. åœ¨ main åˆ†æ”¯å®æ–½é˜¶æ®µ 1ï¼ˆDocker Compose å¤–éƒ¨åŒ–ï¼‰
3. éªŒè¯åŠŸèƒ½å’Œæ€§èƒ½åï¼Œé€æ­¥æ¨è¿›é˜¶æ®µ 2 å’Œ 3

---

**ç»´æŠ¤è€…**: Backend Team
**æœ€åæ›´æ–°**: 2025-10-23
**ç‰ˆæœ¬**: 1.0
