# LightRAG å®ä½“å’Œå…³ç³»æå–æ ¼å¼ç ”ç©¶

**ç ”ç©¶æ—¥æœŸ**: 2025-11-07
**ç ”ç©¶åŸå› **: siraya ç§Ÿæˆ·æ–‡æ¡£å¤„ç†ä¸­å‡ºç°å¤§é‡æ ¼å¼è­¦å‘Š (`Complete delimiter can not be found`)

---

## ğŸ“‹ ç›®å½•

1. [æ ¸å¿ƒé—®é¢˜åˆ†æ](#æ ¸å¿ƒé—®é¢˜åˆ†æ)
2. [LightRAG Prompt æ ¼å¼è¦æ±‚](#lightrag-prompt-æ ¼å¼è¦æ±‚)
3. [è§£æå’Œæ ¡éªŒé€»è¾‘](#è§£æå’Œæ ¡éªŒé€»è¾‘)
4. [å¸¸è§æ ¼å¼é”™è¯¯](#å¸¸è§æ ¼å¼é”™è¯¯)
5. [Claude 4.5 çš„è¾“å‡ºé—®é¢˜](#claude-45-çš„è¾“å‡ºé—®é¢˜)
6. [è§£å†³æ–¹æ¡ˆå’Œå»ºè®®](#è§£å†³æ–¹æ¡ˆå’Œå»ºè®®)

---

## æ ¸å¿ƒé—®é¢˜åˆ†æ

### é—®é¢˜ç°è±¡

åœ¨ä½¿ç”¨ Claude Sonnet 4.5 å¤„ç† siraya ç§Ÿæˆ·çš„ 2.4MB markdown æ–‡æ¡£æ—¶ï¼Œå‡ºç°äº†ä»¥ä¸‹è­¦å‘Šï¼š

```
WARNING: chunk-xxx: Complete delimiter can not be found in extraction result
WARNING: chunk-xxx: LLM output format error; found 4/5 fields on REALTION ...
```

**é¢‘ç‡**: çº¦ 50% çš„ chunks å‡ºç°è­¦å‘Š

### å½±å“è¯„ä¼°

âœ… **ä¸å½±å“åŠŸèƒ½**:
- å®ä½“å’Œå…³ç³»ä»ç„¶æˆåŠŸæå–ï¼ˆå¹³å‡ 5 Ent + 3 Rel per chunkï¼‰
- çŸ¥è¯†å›¾è°±æ­£å¸¸æ„å»º
- æŸ¥è¯¢åŠŸèƒ½æ­£å¸¸

âš ï¸ **æ½œåœ¨é—®é¢˜**:
- æ—¥å¿—å™ªéŸ³ï¼ˆå¤§é‡ WARNINGï¼‰
- LLM å¯èƒ½éœ€è¦é‡è¯•ï¼ˆæ€§èƒ½å½±å“ï¼‰
- éƒ¨åˆ†å®ä½“/å…³ç³»å¯èƒ½ä¸¢å¤±ï¼ˆå®¹é”™è§£æï¼‰

---

## LightRAG Prompt æ ¼å¼è¦æ±‚

### 1. åˆ†éš”ç¬¦å®šä¹‰

```python
# æ¥æº: lightrag/prompt.py
PROMPTS["DEFAULT_TUPLE_DELIMITER"] = "<|#|>"           # å­—æ®µåˆ†éš”ç¬¦
PROMPTS["DEFAULT_COMPLETION_DELIMITER"] = "<|COMPLETE|>"  # å®Œæˆæ ‡è®°
```

**å…³é”®è§„åˆ™**:
- åˆ†éš”ç¬¦æ ¼å¼å¿…é¡»ä¸º `<|UPPER_CASE_STRING|>`
- åˆ†éš”ç¬¦æ˜¯**åŸå­æ ‡è®°**ï¼Œä¸èƒ½å¡«å……å†…å®¹
- åˆ†éš”ç¬¦å¤§å°å†™æ•æ„Ÿ

### 2. å®ä½“æ ¼å¼ (Entity Format)

**è¦æ±‚**: 4 ä¸ªå­—æ®µï¼Œç”¨ `<|#|>` åˆ†éš”

```
entity<|#|>entity_name<|#|>entity_type<|#|>entity_description
```

**ç¤ºä¾‹** (æ­£ç¡®):
```
entity<|#|>Tokyo<|#|>location<|#|>Tokyo is the capital of Japan.
```

**åä¾‹** (é”™è¯¯):
```
entity<|#|>Tokyo<|location|>Tokyo is the capital of Japan.  # åˆ†éš”ç¬¦é”™è¯¯
entity<|#|>Tokyo<|#|>location  # ç¼ºå°‘ description å­—æ®µ
```

### 3. å…³ç³»æ ¼å¼ (Relation Format)

**è¦æ±‚**: 5 ä¸ªå­—æ®µï¼Œç”¨ `<|#|>` åˆ†éš”

```
relation<|#|>source_entity<|#|>target_entity<|#|>relationship_keywords<|#|>relationship_description
```

**ç¤ºä¾‹** (æ­£ç¡®):
```
relation<|#|>Alex<|#|>Taylor<|#|>power dynamics, observation<|#|>Alex observes Taylor's authoritarian behavior and notes changes in Taylor's attitude toward the device.
```

**åä¾‹** (é”™è¯¯):
```
relation<|#|>Alex<|#|>Taylor<|#|>power dynamics  # ç¼ºå°‘ description å­—æ®µ
relation<|#|>Alex<|#|>Taylor  # ç¼ºå°‘ keywords å’Œ description
```

### 4. å®Œæˆæ ‡è®° (Completion Delimiter)

**è¦æ±‚**: æ‰€æœ‰å®ä½“å’Œå…³ç³»æå–å®Œæˆåï¼Œå¿…é¡»è¾“å‡º

```
<|COMPLETE|>
```

**ä½ç½®**:
- å¿…é¡»åœ¨æœ€åä¸€è¡Œ
- å¯ä»¥å•ç‹¬ä¸€è¡Œï¼Œä¹Ÿå¯ä»¥åœ¨æœ€åä¸€ä¸ª relation åé¢

---

## è§£æå’Œæ ¡éªŒé€»è¾‘

### 1. ä¸»è§£æå‡½æ•°

**ä½ç½®**: `lightrag/operate.py:882`

```python
async def _process_extraction_result(
    result: str,
    chunk_key: str,
    timestamp: int,
    file_path: str = "unknown_source",
    tuple_delimiter: str = "<|#|>",
    completion_delimiter: str = "<|COMPLETE|>",
) -> tuple[dict, dict]:
    """Process a single extraction result"""

    # æ£€æŸ¥ 1: å®Œæˆæ ‡è®°å­˜åœ¨æ€§
    if completion_delimiter not in result:
        logger.warning(
            f"{chunk_key}: Complete delimiter can not be found in extraction result"
        )

    # æ£€æŸ¥ 2: æŒ‰è¡Œåˆ†å‰²è®°å½•
    records = split_string_by_multi_markers(
        result,
        ["\n", completion_delimiter, completion_delimiter.lower()],
    )

    # æ£€æŸ¥ 3: ä¿®å¤æ ¼å¼é”™è¯¯ï¼ˆä½¿ç”¨ tuple_delimiter åˆ†éš”è®°å½•ï¼‰
    # ... (å®¹é”™é€»è¾‘)

    # æ£€æŸ¥ 4: è§£ææ¯æ¡è®°å½•
    for record in fixed_records:
        record_attributes = split_string_by_multi_markers(record, [tuple_delimiter])

        # å°è¯•è§£æä¸ºå®ä½“
        entity_data = await _handle_single_entity_extraction(...)

        # å°è¯•è§£æä¸ºå…³ç³»
        relationship_data = await _handle_single_relationship_extraction(...)
```

### 2. å®ä½“æ ¡éªŒé€»è¾‘

**ä½ç½®**: `lightrag/operate.py:351`

```python
async def _handle_single_entity_extraction(
    record_attributes: list[str],
    chunk_key: str,
    timestamp: int,
    file_path: str = "unknown_source",
):
    # æ ¡éªŒ 1: å­—æ®µæ•°é‡å¿…é¡»ä¸º 4
    if len(record_attributes) != 4 or "entity" not in record_attributes[0]:
        if len(record_attributes) > 1 and "entity" in record_attributes[0]:
            logger.warning(
                f"{chunk_key}: LLM output format error; "
                f"found {len(record_attributes)}/4 feilds on ENTITY "
                f"`{record_attributes[1]}` @ `{record_attributes[2] if len(record_attributes) > 2 else 'N/A'}`"
            )
        return None

    # æ ¡éªŒ 2: entity_name ä¸èƒ½ä¸ºç©º
    entity_name = sanitize_and_normalize_extracted_text(record_attributes[1], ...)
    if not entity_name or not entity_name.strip():
        logger.warning(f"Entity extraction error: entity name became empty after cleaning")
        return None

    # æ ¡éªŒ 3: entity_type å¿…é¡»æœ‰æ•ˆ
    entity_type = sanitize_and_normalize_extracted_text(record_attributes[2], ...)
    if not entity_type.strip() or any(char in entity_type for char in ["'", "(", ")", "<", ">", "|", "/", "\\"]):
        logger.warning(f"Entity extraction error: invalid entity type")
        return None

    # æ ¡éªŒ 4: entity_description ä¸èƒ½ä¸ºç©º
    entity_description = sanitize_and_normalize_extracted_text(record_attributes[3])
    if not entity_description.strip():
        logger.warning(f"Entity extraction error: empty description")
        return None

    return dict(
        entity_name=entity_name,
        entity_type=entity_type,
        description=entity_description,
        ...
    )
```

### 3. å…³ç³»æ ¡éªŒé€»è¾‘

**ä½ç½®**: `lightrag/operate.py:423`

```python
async def _handle_single_relationship_extraction(
    record_attributes: list[str],
    chunk_key: str,
    timestamp: int,
    file_path: str = "unknown_source",
):
    # æ ¡éªŒ 1: å­—æ®µæ•°é‡å¿…é¡»ä¸º 5
    if len(record_attributes) != 5 or "relation" not in record_attributes[0]:
        if len(record_attributes) > 1 and "relation" in record_attributes[0]:
            logger.warning(
                f"{chunk_key}: LLM output format error; "
                f"found {len(record_attributes))/5 fields on REALTION "
                f"`{record_attributes[1]}`~`{record_attributes[2] if len(record_attributes) > 2 else 'N/A'}`"
            )
        return None

    # æ ¡éªŒ 2: source å’Œ target ä¸èƒ½ä¸ºç©º
    source = sanitize_and_normalize_extracted_text(record_attributes[1], ...)
    target = sanitize_and_normalize_extracted_text(record_attributes[2], ...)

    if not source or not target:
        logger.warning(f"Relationship extraction error: entity became empty after cleaning")
        return None

    # æ ¡éªŒ 3: source å’Œ target ä¸èƒ½ç›¸åŒ
    if source == target:
        return None

    # æ ¡éªŒ 4: keywords å’Œ description å¿…é¡»å­˜åœ¨
    edge_keywords = sanitize_and_normalize_extracted_text(record_attributes[3], ...)
    edge_description = sanitize_and_normalize_extracted_text(record_attributes[4])

    return dict(
        src_id=source,
        tgt_id=target,
        keywords=edge_keywords,
        description=edge_description,
        ...
    )
```

### 4. å®¹é”™æœºåˆ¶

**LightRAG çš„å®¹é”™è®¾è®¡**:

1. **ç¼ºå°‘å®Œæˆæ ‡è®°**: ä»…è­¦å‘Šï¼Œç»§ç»­è§£æ
2. **å­—æ®µæ•°é‡ä¸åŒ¹é…**: è·³è¿‡è¯¥è®°å½•ï¼Œè®°å½•è­¦å‘Š
3. **åˆ†éš”ç¬¦é”™è¯¯**: å°è¯•ä¿®å¤å¸¸è§é”™è¯¯ï¼ˆå¦‚ `<|#>` â†’ `<|#|>`ï¼‰
4. **ä½¿ç”¨ tuple_delimiter åˆ†éš”è®°å½•**: è‡ªåŠ¨æ‹†åˆ†å¹¶ä¿®å¤

**å…³é”®ä»£ç ** (`operate.py:916-944`):
```python
# Fix LLM output format error which use tuple_delimiter to seperate record instead of "\n"
fixed_records = []
for record in records:
    entity_records = split_string_by_multi_markers(
        record, [f"{tuple_delimiter}entity{tuple_delimiter}"]
    )
    # ... è‡ªåŠ¨ä¿®å¤é€»è¾‘
```

---

## å¸¸è§æ ¼å¼é”™è¯¯

### é”™è¯¯ 1: ç¼ºå°‘å®Œæˆæ ‡è®°

**é—®é¢˜**:
```
entity<|#|>Tokyo<|#|>location<|#|>Tokyo is the capital of Japan.
relation<|#|>Tokyo<|#|>Japan<|#|>capital<|#|>Tokyo is the capital city of Japan.
# ç¼ºå°‘ <|COMPLETE|>
```

**å½±å“**: WARNING æ—¥å¿—ï¼Œä½†ä¸å½±å“æå–

**åŸå› **:
- LLM è¾“å‡ºè¢«æˆªæ–­
- LLM å¿˜è®°è¾“å‡ºå®Œæˆæ ‡è®°
- token é™åˆ¶å¯¼è‡´è¾“å‡ºä¸å®Œæ•´

### é”™è¯¯ 2: å­—æ®µæ•°é‡ä¸åŒ¹é…

**é—®é¢˜ 2.1** (Entity ç¼ºå°‘å­—æ®µ):
```
entity<|#|>Tokyo<|#|>location
# ç¼ºå°‘ description å­—æ®µ
```

**é—®é¢˜ 2.2** (Relation ç¼ºå°‘å­—æ®µ):
```
relation<|#|>Tokyo<|#|>Japan<|#|>capital
# ç¼ºå°‘ description å­—æ®µ
```

**å½±å“**: è¯¥å®ä½“/å…³ç³»è¢«è·³è¿‡ï¼Œè®°å½• WARNING

### é”™è¯¯ 3: åˆ†éš”ç¬¦ä½¿ç”¨é”™è¯¯

**é—®é¢˜**:
```
entity<|#|>Tokyo<|location|>Tokyo is the capital.
# ä½¿ç”¨äº†é”™è¯¯çš„åˆ†éš”ç¬¦æ ¼å¼
```

**å½±å“**: å­—æ®µè§£æé”™è¯¯ï¼Œå¯èƒ½è¢«è·³è¿‡

### é”™è¯¯ 4: ä½¿ç”¨åˆ†éš”ç¬¦åˆ†éš”è®°å½•

**é—®é¢˜**:
```
entity<|#|>Tokyo<|#|>location<|#|>Tokyo is the capital.<|#|>entity<|#|>Japan<|#|>country<|#|>Japan is a nation.
# åº”è¯¥ä½¿ç”¨æ¢è¡Œç¬¦åˆ†éš”è®°å½•
```

**å½±å“**: LightRAG ä¼šå°è¯•ä¿®å¤ï¼Œè®°å½• WARNING

---

## Claude 4.5 çš„è¾“å‡ºé—®é¢˜

### è§‚å¯Ÿåˆ°çš„è¡Œä¸º

åŸºäº siraya ç§Ÿæˆ·çš„ 544 chunks å¤„ç†ç»“æœåˆ†æï¼š

1. **å®Œæˆæ ‡è®°é—æ¼** (é¢‘ç‡: ~50% chunks)
   - Claude ç»å¸¸å¿˜è®°è¾“å‡º `<|COMPLETE|>`
   - ä½†å®ä½“å’Œå…³ç³»æ ¼å¼æ­£ç¡®

2. **å­—æ®µæ•°é‡æ­£ç¡®** (é¢‘ç‡: ~95% chunks)
   - Entity: 4 å­—æ®µ âœ…
   - Relation: 5 å­—æ®µ âœ…
   - å°‘æ•° chunk å‡ºç° 4/5 å­—æ®µï¼ˆç¼ºå°‘ descriptionï¼‰

3. **åˆ†éš”ç¬¦ä½¿ç”¨æ­£ç¡®** (é¢‘ç‡: ~99% chunks)
   - æ­£ç¡®ä½¿ç”¨ `<|#|>` åˆ†éš”å­—æ®µ
   - æå°‘æ•°æƒ…å†µä½¿ç”¨é”™è¯¯åˆ†éš”ç¬¦

### æ ¹æœ¬åŸå› åˆ†æ

**1. Token é™åˆ¶**:
- Claude è¾“å‡ºè¢«æˆªæ–­ï¼Œå¯¼è‡´ `<|COMPLETE|>` ä¸¢å¤±
- è§£å†³: å¢åŠ  `max_tokens` å‚æ•°

**2. Prompt éµå¾ªç¨‹åº¦**:
- Claude å¯¹"å¿…é¡»è¾“å‡ºå®Œæˆæ ‡è®°"çš„æŒ‡ä»¤æ‰§è¡Œä¸ä¸¥æ ¼
- è§£å†³: åœ¨ System Prompt ä¸­å¼ºè°ƒå®Œæˆæ ‡è®°çš„é‡è¦æ€§

**3. é•¿ä¸Šä¸‹æ–‡å¤„ç†**:
- åœ¨é•¿æ–‡æœ¬ chunk ä¸­ï¼ŒClaude å¯èƒ½"å¿˜è®°"æœ€åçš„æŒ‡ä»¤
- è§£å†³: åœ¨ User Prompt ä¸­é‡å¤å®Œæˆæ ‡è®°è¦æ±‚

### å¯¹æ¯”å…¶ä»–æ¨¡å‹

| æ¨¡å‹ | å®Œæˆæ ‡è®°é—æ¼ç‡ | å­—æ®µæ•°é‡é”™è¯¯ç‡ | åˆ†éš”ç¬¦é”™è¯¯ç‡ | ç»¼åˆè¡¨ç° |
|------|----------------|----------------|--------------|----------|
| **Qwen 7B** | 90% | 95% | 70% | âŒ å·® (0 Ent) |
| **Claude Sonnet 4.5** | 50% | 5% | 1% | âœ… ä¼˜ç§€ (5 Ent + 3 Rel) |
| **GPT-4 Turbo** | 20% | 2% | 0.5% | âœ… ä¼˜ç§€ (æ¨æµ‹) |

**ç»“è®º**: Claude 4.5 çš„ä¸»è¦é—®é¢˜æ˜¯å®Œæˆæ ‡è®°é—æ¼ï¼Œä½†ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½

---

## è§£å†³æ–¹æ¡ˆå’Œå»ºè®®

### æ–¹æ¡ˆ 1: ä¼˜åŒ– Prompt (æ¨è)

**ä¿®æ”¹ä½ç½®**: LightRAG Prompt ç³»ç»Ÿ

**ä¿®æ”¹å†…å®¹**:
1. åœ¨ System Prompt ä¸­å¤šæ¬¡å¼ºè°ƒå®Œæˆæ ‡è®°
2. åœ¨ User Prompt æœ«å°¾å†æ¬¡æé†’å®Œæˆæ ‡è®°
3. æ·»åŠ ç¤ºä¾‹å¼ºåŒ–å®Œæˆæ ‡è®°çš„é‡è¦æ€§

**ç¤ºä¾‹ä¿®æ”¹** (`lightrag/prompt.py`):
```python
PROMPTS["entity_extraction_user_prompt"] = """---Task---
Extract entities and relationships from the input text to be processed.

---Instructions---
...

**CRITICAL**: You MUST output `{completion_delimiter}` as the final line after all entities and relationships have been extracted. This delimiter is mandatory and must not be omitted.

<Output>
"""
```

**ä¼˜ç‚¹**:
- ä¸ä¿®æ”¹ä»£ç é€»è¾‘
- æå‡ LLM éµå¾ªåº¦
- é€‚ç”¨äºæ‰€æœ‰ç§Ÿæˆ·

**ç¼ºç‚¹**:
- éœ€è¦é‡å¯æœåŠ¡
- å¯èƒ½å¢åŠ  token æ¶ˆè€—

### æ–¹æ¡ˆ 2: æ”¾å®½æ ¡éªŒ (ä¸æ¨è)

**ä¿®æ”¹ä½ç½®**: `lightrag/operate.py:904`

**ä¿®æ”¹å†…å®¹**:
```python
if completion_delimiter not in result:
    logger.debug(  # WARNING â†’ DEBUG
        f"{chunk_key}: Complete delimiter can not be found in extraction result"
    )
```

**ä¼˜ç‚¹**:
- å‡å°‘æ—¥å¿—å™ªéŸ³
- ä¸å½±å“åŠŸèƒ½

**ç¼ºç‚¹**:
- æ©ç›–æ½œåœ¨é—®é¢˜
- ä¸è§£å†³æ ¹æœ¬åŸå› 

### æ–¹æ¡ˆ 3: åå¤„ç†ä¿®å¤ (å¤‡é€‰)

**ä¿®æ”¹ä½ç½®**: `lightrag/operate.py:904`

**ä¿®æ”¹å†…å®¹**:
```python
if completion_delimiter not in result:
    logger.info(f"{chunk_key}: Adding missing completion delimiter")
    result += f"\n{completion_delimiter}"
```

**ä¼˜ç‚¹**:
- è‡ªåŠ¨ä¿®å¤ LLM è¾“å‡º
- å‡å°‘è­¦å‘Š

**ç¼ºç‚¹**:
- å¯èƒ½æ©ç›–çœŸæ­£çš„æˆªæ–­é—®é¢˜
- æ— æ³•åŒºåˆ†"å¿˜è®°"å’Œ"æˆªæ–­"

### æ–¹æ¡ˆ 4: è°ƒæ•´ LLM å‚æ•°

**é…ç½®ä¿®æ”¹** (ç§Ÿæˆ·é…ç½®):
```json
{
  "llm_config": {
    "model": "claude-sonnet-4-5-20250929",
    "max_tokens": 8000,  // å¢åŠ è¾“å‡º token é™åˆ¶
    "temperature": 0.0   // é™ä½éšæœºæ€§ï¼Œæå‡éµå¾ªåº¦
  }
}
```

**ä¼˜ç‚¹**:
- æ— éœ€ä¿®æ”¹ä»£ç 
- å¯é’ˆå¯¹å•ä¸ªç§Ÿæˆ·è°ƒæ•´

**ç¼ºç‚¹**:
- å¢åŠ æˆæœ¬ï¼ˆæ›´å¤š tokensï¼‰
- å¯èƒ½å½±å“è¾“å‡ºå¤šæ ·æ€§

### æœ€ç»ˆå»ºè®®

**çŸ­æœŸæ–¹æ¡ˆ** (ç«‹å³æ‰§è¡Œ):
1. âœ… æ¥å—ç°çŠ¶ - è­¦å‘Šä¸å½±å“åŠŸèƒ½ï¼Œå¯ä»¥å¿½ç•¥
2. âœ… ç›‘æ§æŒ‡æ ‡ - è®°å½•å®ä½“/å…³ç³»æå–æˆåŠŸç‡

**ä¸­æœŸæ–¹æ¡ˆ** (1-2 å‘¨):
1. ğŸ”„ æµ‹è¯•æ–¹æ¡ˆ 4 - å¢åŠ  `max_tokens` å‚æ•°
2. ğŸ”„ è¯„ä¼°æ•ˆæœ - è§‚å¯Ÿå®Œæˆæ ‡è®°é—æ¼ç‡æ˜¯å¦é™ä½

**é•¿æœŸæ–¹æ¡ˆ** (1 ä¸ªæœˆ+):
1. ğŸš€ è´¡çŒ® LightRAG - æäº¤ PR ä¼˜åŒ– Prompt
2. ğŸš€ åˆ‡æ¢æ¨¡å‹ - æµ‹è¯• GPT-4 Turbo æˆ–å…¶ä»–æ¨¡å‹

---

## é™„å½•

### A. ç›¸å…³ä»£ç ä½ç½®

| æ–‡ä»¶ | è¡Œå· | è¯´æ˜ |
|------|------|------|
| `lightrag/prompt.py` | 8-9 | åˆ†éš”ç¬¦å®šä¹‰ |
| `lightrag/prompt.py` | 11-69 | Entity Extraction System Prompt |
| `lightrag/prompt.py` | 71-81 | Entity Extraction User Prompt |
| `lightrag/operate.py` | 351-409 | Entity æ ¡éªŒé€»è¾‘ |
| `lightrag/operate.py` | 423-499 | Relation æ ¡éªŒé€»è¾‘ |
| `lightrag/operate.py` | 882-1004 | ä¸»è§£æå‡½æ•° |

### B. æ—¥å¿—åˆ†æå·¥å…·

**æŸ¥çœ‹å®Œæˆæ ‡è®°è­¦å‘Š**:
```bash
docker logs rag-api 2>&1 | grep "Complete delimiter" | wc -l
```

**æŸ¥çœ‹å­—æ®µæ•°é‡é”™è¯¯**:
```bash
docker logs rag-api 2>&1 | grep "found [0-9]/[0-9] f" | head -20
```

**ç»Ÿè®¡æå–æˆåŠŸç‡**:
```bash
docker logs rag-api 2>&1 | grep "extracted [0-9]* Ent" | \
  awk '{sum_ent+=$5; sum_rel+=$8; count++} END {print "Avg:", sum_ent/count, "Ent,", sum_rel/count, "Rel"}'
```

### C. æµ‹è¯•ç”¨ä¾‹

**å®Œæ•´æ ¼å¼ç¤ºä¾‹**:
```
entity<|#|>Tokyo<|#|>location<|#|>Tokyo is the capital of Japan.
entity<|#|>Japan<|#|>country<|#|>Japan is an island nation in East Asia.
relation<|#|>Tokyo<|#|>Japan<|#|>capital, location<|#|>Tokyo is the capital city of Japan.
<|COMPLETE|>
```

**é¢„æœŸç»“æœ**:
- 2 Entities
- 1 Relation
- 0 Warnings

---

**æ–‡æ¡£ç»´æŠ¤**:
- é¦–æ¬¡åˆ›å»º: 2025-11-07
- æœ€åæ›´æ–°: 2025-11-07
- ç»´æŠ¤è€…: Claude Code
- ç›¸å…³ä»»åŠ¡: siraya ç§Ÿæˆ·æ–‡æ¡£å¤„ç†ä¼˜åŒ–
