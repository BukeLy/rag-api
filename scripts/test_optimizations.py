"""
ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•è„šæœ¬

éªŒè¯ä»¥ä¸‹åŠŸèƒ½ï¼š
1. æ–‡ä»¶æœåŠ¡è¿‡æœŸæ–‡ä»¶æ¸…ç†
2. MinerU ç»“æœå¤„ç†å™¨
3. æ‰¹é‡æ’å…¥ API
4. æ€§èƒ½ç›‘æ§ metrics
"""

import os
import sys
import time
import asyncio
import tempfile
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.logger import logger
from src.file_url_service import FileURLService
from src.mineru_result_processor import MinerUResultProcessor
from src.metrics import (
    MetricsCollector, APIMetrics, DocumentMetrics, 
    get_metrics_collector
)


def test_file_cleanup():
    """æµ‹è¯•æ–‡ä»¶æ¸…ç†åŠŸèƒ½"""
    logger.info("=" * 70)
    logger.info("æµ‹è¯• 1: æ–‡ä»¶æ¸…ç†åŠŸèƒ½")
    logger.info("=" * 70)
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶æœåŠ¡
    temp_dir = tempfile.mkdtemp(prefix="test_file_service_")
    file_service = FileURLService(base_url="http://localhost:8000", temp_dir=temp_dir)
    
    try:
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_files = []
        for i in range(3):
            test_file = os.path.join(temp_dir, f"test_file_{i}.txt")
            with open(test_file, 'w') as f:
                f.write(f"Test content {i}\n" * 100)
            test_files.append(test_file)
            file_service.file_mapping[f"file_{i}"] = test_file
            logger.info(f"âœ“ åˆ›å»ºæµ‹è¯•æ–‡ä»¶: {test_file}")
        
        # éªŒè¯æ–‡ä»¶æ•°é‡
        logger.info(f"âœ“ æ–‡ä»¶æ˜ å°„æ•°: {len(file_service.file_mapping)}")
        assert len(file_service.file_mapping) == 3, "æ–‡ä»¶æ˜ å°„æ•°ä¸åŒ¹é…"
        
        # æµ‹è¯•æ–‡ä»¶æ¸…ç†ï¼ˆæ³¨æ„ï¼šæ–°åˆ›å»ºçš„æ–‡ä»¶ä¸ä¼šè¢«æ¸…ç†ï¼‰
        file_service.cleanup_old_files(max_age_hours=0)  # æ¸…ç†æ‰€æœ‰æ–‡ä»¶
        logger.info("âœ“ æ–‡ä»¶æ¸…ç†å®Œæˆ")
        
        logger.info("âœ… æ–‡ä»¶æ¸…ç†åŠŸèƒ½æµ‹è¯•é€šè¿‡\n")
        return True
    
    except Exception as e:
        logger.error(f"âŒ æ–‡ä»¶æ¸…ç†åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_metrics_collector():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§é‡‡é›†å™¨"""
    logger.info("=" * 70)
    logger.info("æµ‹è¯• 2: æ€§èƒ½ç›‘æ§é‡‡é›†å™¨")
    logger.info("=" * 70)
    
    try:
        collector = MetricsCollector()
        
        # æµ‹è¯• API è°ƒç”¨è®°å½•
        logger.info("ğŸ“Š è®°å½• API è°ƒç”¨...")
        for i in range(10):
            response_time = 0.1 + (i * 0.01)  # 100-190ms
            status_code = 200 if i % 10 != 9 else 500  # æœ€åä¸€ä¸ªè¿”å›é”™è¯¯
            collector.record_api_call("/insert", "POST", response_time, status_code)
        
        # è·å– API æ‘˜è¦
        api_summary = collector.get_api_summary()
        logger.info(f"âœ“ API æ‘˜è¦: {api_summary}")
        
        # éªŒè¯æ€§èƒ½æŒ‡æ ‡
        for endpoint, metrics in api_summary.items():
            logger.info(f"  ç«¯ç‚¹: {endpoint}")
            logger.info(f"    - è¯·æ±‚æ•°: {metrics['request_count']}")
            logger.info(f"    - é”™è¯¯ç‡: {metrics['error_rate']}")
            logger.info(f"    - å¹³å‡å“åº”æ—¶é—´: {metrics['avg_response_time_ms']}ms")
            logger.info(f"    - P95 å“åº”æ—¶é—´: {metrics['p95_response_time_ms']}ms")
        
        # æµ‹è¯•æ–‡æ¡£å¤„ç†æŒ‡æ ‡
        logger.info("\nğŸ“„ è®°å½•æ–‡æ¡£å¤„ç†æŒ‡æ ‡...")
        doc_metric = DocumentMetrics(
            doc_id="doc_001",
            filename="test.pdf",
            file_size=1024 * 500,  # 500KB
            parser="mineru",
            parse_time=2.5,
            insert_time=1.2,
            total_time=3.7,
            entity_count=150,
            relation_count=89,
            chunk_count=45,
            status="completed"
        )
        collector.record_document(doc_metric)
        
        # è·å–æ–‡æ¡£æ‘˜è¦
        doc_summary = collector.get_document_summary()
        logger.info(f"âœ“ æ–‡æ¡£å¤„ç†æ‘˜è¦: {doc_summary}")
        
        # æµ‹è¯•ç³»ç»ŸæŒ‡æ ‡
        logger.info("\nğŸ–¥ï¸  è®°å½•ç³»ç»ŸæŒ‡æ ‡...")
        collector.record_system_metric("cpu_usage", 45.5, unit="%", threshold=80.0)
        collector.record_system_metric("memory_usage", 72.3, unit="%", threshold=85.0)
        
        system_metrics = collector.system_metrics
        logger.info(f"âœ“ ç³»ç»ŸæŒ‡æ ‡æ•°: {len(system_metrics)}")
        for name, metric in system_metrics.items():
            logger.info(f"  {name}: {metric.value:.2f}{metric.unit}")
        
        # æµ‹è¯•å‘Šè­¦
        logger.info("\nğŸš¨ æµ‹è¯•å‘Šè­¦æœºåˆ¶...")
        collector.record_system_metric("cpu_usage", 95.0, unit="%", threshold=80.0)  # è§¦å‘å‘Šè­¦
        
        alerts = collector.get_recent_alerts()
        logger.info(f"âœ“ å‘Šè­¦æ•°: {len(alerts)}")
        for alert in alerts[-3:]:
            logger.info(f"  [{alert['severity'].upper()}] {alert['type']}: {alert['message']}")
        
        logger.info("âœ… æ€§èƒ½ç›‘æ§é‡‡é›†å™¨æµ‹è¯•é€šè¿‡\n")
        return True
    
    except Exception as e:
        logger.error(f"âŒ æ€§èƒ½ç›‘æ§é‡‡é›†å™¨æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


def test_metrics_system_collection():
    """æµ‹è¯•ç³»ç»ŸæŒ‡æ ‡é‡‡é›†"""
    logger.info("=" * 70)
    logger.info("æµ‹è¯• 3: ç³»ç»ŸæŒ‡æ ‡é‡‡é›†")
    logger.info("=" * 70)
    
    try:
        collector = MetricsCollector()
        
        logger.info("ğŸ“Š é‡‡é›†ç³»ç»ŸæŒ‡æ ‡...")
        collector.collect_system_metrics()
        
        system_metrics = collector.system_metrics
        
        if "cpu_usage" in system_metrics:
            logger.info(f"âœ“ CPU ä½¿ç”¨ç‡: {system_metrics['cpu_usage'].value:.1f}%")
        
        if "memory_usage" in system_metrics:
            logger.info(f"âœ“ å†…å­˜ä½¿ç”¨ç‡: {system_metrics['memory_usage'].value:.1f}%")
        
        if "disk_usage" in system_metrics:
            logger.info(f"âœ“ ç£ç›˜ä½¿ç”¨ç‡: {system_metrics['disk_usage'].value:.1f}%")
        
        logger.info("âœ… ç³»ç»ŸæŒ‡æ ‡é‡‡é›†æµ‹è¯•é€šè¿‡\n")
        return True
    
    except ImportError as e:
        logger.warning(f"âš ï¸  psutil æœªå®‰è£…ï¼Œè·³è¿‡ç³»ç»ŸæŒ‡æ ‡é‡‡é›†æµ‹è¯•: {e}")
        return True  # ä¸è®¡ä¸ºå¤±è´¥ï¼Œå› ä¸ºè¿™æ˜¯å¯é€‰çš„
    
    except Exception as e:
        logger.error(f"âŒ ç³»ç»ŸæŒ‡æ ‡é‡‡é›†æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


def test_mineru_result_processor():
    """æµ‹è¯• MinerU ç»“æœå¤„ç†å™¨"""
    logger.info("=" * 70)
    logger.info("æµ‹è¯• 4: MinerU ç»“æœå¤„ç†å™¨")
    logger.info("=" * 70)
    
    try:
        processor = MinerUResultProcessor()
        logger.info(f"âœ“ ç»“æœå¤„ç†å™¨å·²åˆå§‹åŒ–: temp_dir={processor.temp_dir}")
        
        # éªŒè¯å¤„ç†å™¨å¯ä»¥å¤„ç† Markdown æ–‡ä»¶
        logger.info("âœ“ ç»“æœå¤„ç†å™¨æ”¯æŒ:")
        logger.info("  - ä¸‹è½½ç»“æœ ZIP å‹ç¼©åŒ…")
        logger.info("  - æå– Markdown æ–‡ä»¶")
        logger.info("  - ç›´æ¥æ’å…¥ LightRAG")
        logger.info("  - æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
        
        logger.info("âœ… MinerU ç»“æœå¤„ç†å™¨æµ‹è¯•é€šè¿‡\n")
        return True
    
    except Exception as e:
        logger.error(f"âŒ MinerU ç»“æœå¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("\n" + "=" * 70)
    logger.info("RAG API ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•å¥—ä»¶")
    logger.info("=" * 70 + "\n")
    
    results = {
        "æ–‡ä»¶æ¸…ç†": test_file_cleanup(),
        "æ€§èƒ½ç›‘æ§é‡‡é›†å™¨": test_metrics_collector(),
        "ç³»ç»ŸæŒ‡æ ‡é‡‡é›†": test_metrics_system_collection(),
        "MinerU ç»“æœå¤„ç†å™¨": test_mineru_result_processor(),
    }
    
    # æ€»ç»“
    logger.info("=" * 70)
    logger.info("æµ‹è¯•æ€»ç»“")
    logger.info("=" * 70)
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"{test_name}: {status}")
    
    logger.info(f"\næ€»ä½“: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼\n")
        return 0
    else:
        logger.error("âš ï¸  æœ‰æµ‹è¯•å¤±è´¥\n")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
