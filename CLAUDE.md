# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Language Preference

  **Default Response Language**: Chinese (Simplified)
  - All responses, explanations, and documentation
  should be in Chinese
  - Thinking process can remain in English
  - Code comments and variable names should follow
  standard English conventions
  - Git commits should be in Chinese

## Project Overview

This is a **multi-tenant** multimodal RAG (Retrieval-Augmented Generation) API service built with FastAPI, combining RAG-Anything and LightRAG for document processing and intelligent querying.

**Key Architecture**: Multi-Tenant LightRAG + Multiple Parsers
- **Multi-tenant isolation**: Each tenant has isolated LightRAG instance (via workspace)
- **Instance pool management**: LRU cache (max 50 instances by default)
- **Shared resources**: LLM/Embedding functions shared across tenants
- **MinerU parser**: Powerful multimodal parsing (OCR, tables, equations) with high memory usage
- **Docling parser**: Lightweight fast parsing for simple documents
- **Direct LightRAG query**: Bypasses parsers for 95% of text queries, optimizing performance

## Branch Strategy

- **`main` branch** (å”¯ä¸€ä¸»åˆ†æ”¯)
  - æ‰€æœ‰ä»£ç éƒ½åœ¨æ­¤åˆ†æ”¯å¼€å‘å’Œéƒ¨ç½²
  - ç”Ÿäº§çŽ¯å¢ƒå’Œå¼€å‘çŽ¯å¢ƒé€šè¿‡ä¸åŒçš„ docker-compose æ–‡ä»¶åŒºåˆ†
  - æ–°åŠŸèƒ½å¼€å‘é€šè¿‡ Pull Request æµç¨‹åˆå¹¶

### å¼€å‘æµç¨‹ (Pull Request Workflow)

1. **åˆ›å»ºåŠŸèƒ½åˆ†æ”¯**
   ```bash
   git checkout -b feature/your-feature-name
   ```

2. **å¼€å‘å’Œæäº¤**
   ```bash
   git add .
   git commit -m "feat: åŠŸèƒ½æè¿°"
   ```

3. **æŽ¨é€åˆ°è¿œç«¯å¹¶åˆ›å»º PR**
   ```bash
   git push origin feature/your-feature-name
   # åœ¨ GitHub ä¸Šåˆ›å»º Pull Request
   ```

4. **PR åˆå¹¶åŽåˆ é™¤åŠŸèƒ½åˆ†æ”¯**
   ```bash
   git checkout main
   git pull origin main
   git branch -d feature/your-feature-name
   git push origin --delete feature/your-feature-name
   ```

## Deployment Commands

### ä½¿ç”¨ä¸€é”®éƒ¨ç½²è„šæœ¬ï¼ˆæŽ¨èï¼‰

```bash
./deploy.sh
# ä¼šæç¤ºé€‰æ‹©éƒ¨ç½²æ¨¡å¼ï¼š
# 1) ç”Ÿäº§æ¨¡å¼ (Production)
# 2) å¼€å‘æ¨¡å¼ (Development)
```

### ç”Ÿäº§æ¨¡å¼éƒ¨ç½²

```bash
# å¯åŠ¨æœåŠ¡
docker compose -f docker-compose.yml up -d

# æŸ¥çœ‹æ—¥å¿—
docker compose -f docker-compose.yml logs -f

# é‡å¯æœåŠ¡
docker compose -f docker-compose.yml restart

# åœæ­¢æœåŠ¡
docker compose -f docker-compose.yml down
```

### å¼€å‘æ¨¡å¼éƒ¨ç½²ï¼ˆä»£ç çƒ­é‡è½½ï¼‰

```bash
# å¯åŠ¨æœåŠ¡ï¼ˆä»£ç å¤–æŒ‚ï¼Œæ”¯æŒçƒ­é‡è½½ï¼‰
docker compose -f docker-compose.dev.yml up -d

# æˆ–ä½¿ç”¨å¿«æ·è„šæœ¬
./scripts/dev.sh

# æŸ¥çœ‹æ—¥å¿—
docker compose -f docker-compose.dev.yml logs -f

# åœæ­¢æœåŠ¡
docker compose -f docker-compose.dev.yml down
```

### Testing & Monitoring
```bash
# Monitor service health
./scripts/monitor.sh

# Backup data
./scripts/backup.sh

# Update deployment
./scripts/update.sh

# Performance monitoring
./scripts/monitor_performance.sh

# Concurrent performance test
./scripts/test_concurrent_perf.sh
```

## LightRAG WebUIï¼ˆçŸ¥è¯†å›¾è°±å¯è§†åŒ–ï¼‰

é¡¹ç›®é›†æˆäº† LightRAG å®˜æ–¹ WebUIï¼Œä¸Ž rag-api å½¢æˆ**äº’è¡¥å…³ç³»**ï¼Œå®Œå…¨å…¼å®¹å¤šç§Ÿæˆ·æž¶æž„ã€‚

### ðŸŽ¯ ä¸ºä»€ä¹ˆéœ€è¦ä¸¤è€…ï¼Ÿ

**rag-api çš„ç‹¬ç‰¹ä»·å€¼**ï¼ˆWebUI æ— æ³•æ›¿ä»£ï¼‰ï¼š
- ðŸ–¼ï¸ **å¼ºå¤§æ–‡æ¡£è§£æž**ï¼šMinerUï¼ˆOCR/è¡¨æ ¼/å…¬å¼ï¼‰+ Docling æ™ºèƒ½é€‰æ‹©
- ðŸ“¦ **æ‰¹é‡å¤„ç†**ï¼š`/batch` ç«¯ç‚¹æ”¯æŒ 100 æ–‡ä»¶åŒæ—¶å¤„ç†
- ðŸ¢ **å¤šç§Ÿæˆ·æž¶æž„**ï¼šå®Œæ•´çš„ç§Ÿæˆ·éš”ç¦»å’Œå®žä¾‹æ± ç®¡ç†
- ðŸ¤– **ç¼–ç¨‹é›†æˆ**ï¼šRESTful APIï¼Œé€‚åˆè‡ªåŠ¨åŒ–æµç¨‹
- âš¡ **æ€§èƒ½ä¼˜åŒ–**ï¼šå®šåˆ¶å¹¶å‘æŽ§åˆ¶ã€ç¼“å­˜ç­–ç•¥

**LightRAG WebUI çš„ç‹¬ç‰¹ä»·å€¼**ï¼ˆrag-api æ²¡æœ‰ï¼‰ï¼š
- ðŸ“Š **çŸ¥è¯†å›¾è°±å¯è§†åŒ–**ï¼šäº¤äº’å¼æŸ¥çœ‹å®žä½“å’Œå…³ç³»
- ðŸ‘¥ **ç”¨æˆ·å‹å¥½ç•Œé¢**ï¼šéžæŠ€æœ¯ç”¨æˆ·ä¹Ÿèƒ½ä½¿ç”¨
- ðŸ” **å¿«é€Ÿè°ƒè¯•**ï¼šéªŒè¯æ–‡æ¡£æ˜¯å¦æ­£ç¡®æ’å…¥
- ðŸŽ¯ **æ¼”ç¤ºå±•ç¤º**ï¼šé€‚åˆå‘å›¢é˜Ÿå±•ç¤ºç³»ç»Ÿ

**æŽ¨èå·¥ä½œæµ**ï¼š
```
æ–‡æ¡£å¯¼å…¥ â†’ rag-apiï¼ˆæ‰¹é‡+å¼ºè§£æž+å¤šç§Ÿæˆ·ï¼‰â†’ å¤–éƒ¨å­˜å‚¨ â† WebUIï¼ˆå¯è§†åŒ–æŒ‡å®šç§Ÿæˆ·ï¼‰
                                             â†“
                              ç”Ÿäº§æŸ¥è¯¢ â† rag-apiï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
```

### ðŸ”‘ å¤šç§Ÿæˆ·å…¼å®¹æ€§

WebUI é€šè¿‡ `LIGHTRAG_WEBUI_WORKSPACE` çŽ¯å¢ƒå˜é‡è®¿é—®æŒ‡å®šç§Ÿæˆ·çš„æ•°æ®ï¼š
- **é»˜è®¤ workspace**: `default`ï¼ˆå¯è§†åŒ– `tenant_id=default` çš„æ•°æ®ï¼‰
- **åˆ‡æ¢ç§Ÿæˆ·**: ä¿®æ”¹ `.env` ä¸­çš„ `LIGHTRAG_WEBUI_WORKSPACE=tenant_a` åŽé‡å¯ WebUI
- **æ•°æ®åŒæ­¥**: WebUI å’Œ rag-api å…±äº«åŒä¸€å¥—å¤–éƒ¨å­˜å‚¨ï¼ˆRedis/Neo4j/PostgreSQLï¼‰
- **å®žæ—¶å¯è§**: é€šè¿‡ rag-api æ’å…¥çš„æ•°æ®ç«‹å³åœ¨ WebUI ä¸­å¯è§

### åŠŸèƒ½ç‰¹æ€§
- **å¯è§†åŒ–çŸ¥è¯†å›¾è°±**ï¼šäº¤äº’å¼æŸ¥çœ‹å®žä½“å’Œå…³ç³»
- **æ–‡æ¡£ç®¡ç†**ï¼šä¸Šä¼ ã€æŸ¥çœ‹å’Œç®¡ç†æ–‡æ¡£
- **æŸ¥è¯¢ç•Œé¢**ï¼šé€šè¿‡ UI æ‰§è¡Œ RAG æŸ¥è¯¢
- **å¤šæ¨¡å¼æ”¯æŒ**ï¼šæ”¯æŒ naiveã€localã€globalã€hybrid ç­‰æŸ¥è¯¢æ¨¡å¼

### è®¿é—®æ–¹å¼
WebUI æœåŠ¡é»˜è®¤åœ¨ **9621 ç«¯å£**å¯åŠ¨ï¼š
```
æœ¬åœ°è®¿é—®ï¼šhttp://localhost:9621/webui/
è¿œç¨‹æœåŠ¡å™¨ï¼ˆdevï¼‰ï¼šhttp://45.78.223.205:9621/webui/
API æ–‡æ¡£ï¼šhttp://45.78.223.205:9621/docs
```

### å¯åŠ¨/åœæ­¢ WebUI
```bash
# å•ç‹¬å¯åŠ¨ WebUI
docker compose up -d lightrag-webui

# æŸ¥çœ‹ WebUI æ—¥å¿—
docker compose logs -f lightrag-webui

# åˆ‡æ¢åˆ°å…¶ä»–ç§Ÿæˆ·ï¼ˆä¿®æ”¹ .env åŽé‡å¯ï¼‰
docker compose restart lightrag-webui

# åœæ­¢ WebUIï¼ˆä¸å½±å“ rag-apiï¼‰
docker compose stop lightrag-webui
```

### è®¿é—®æŽ§åˆ¶ï¼ˆå¯é€‰ï¼‰
åœ¨ `.env` ä¸­é…ç½®ï¼š
```bash
# API Key è®¤è¯
LIGHTRAG_API_KEY=your_secret_key

# Web UI ç™»å½•è´¦å·ï¼ˆJSON æ ¼å¼ï¼‰
LIGHTRAG_AUTH_ACCOUNTS='[{"username": "admin", "password": "your_password"}]'
```

è¯¦ç»†æ–‡æ¡£è¯·å‚è€ƒï¼š[docs/LIGHTRAG_WEBUI_INTEGRATION.md](docs/LIGHTRAG_WEBUI_INTEGRATION.md)

## Remote Deployment

### Testing Server
- **Host**: 45.78.223.205
- **SSH Access**: `ssh -i /Users/chengjie/Downloads/chengjie.pem root@45.78.223.205`
- **Deployment Method**: Git-based deployment via GitHub
- **Environment**: ä½¿ç”¨å¼€å‘æ¨¡å¼ï¼ˆdocker-compose.dev.ymlï¼‰æ”¯æŒä»£ç çƒ­é‡è½½

### Deployment Workflow

**Three-Way Sync Architecture**:
```
Local Machine â”€â”€git pushâ”€â”€> GitHub â”€â”€git pullâ”€â”€> Remote Server (45.78.223.205)
```

All code changes must be pushed to GitHub first to ensure synchronization across all three endpoints:
1. Local development machine
2. GitHub repository (central source of truth)
3. Testing server

### Deploying Code to Testing Server (45.78.223.205)

**æŽ¨èæ–¹å¼ï¼šé€šè¿‡ PR åˆå¹¶åŽéƒ¨ç½²**

```bash
# 1. æœ¬åœ°å¼€å‘ï¼šåˆ›å»ºåŠŸèƒ½åˆ†æ”¯
git checkout -b feature/your-feature-name

# 2. å¼€å‘å¹¶æäº¤
git add .
git commit -m "feat: åŠŸèƒ½æè¿°"
git push origin feature/your-feature-name

# 3. åœ¨ GitHub åˆ›å»º PR å¹¶åˆå¹¶åˆ° main

# 4. SSH åˆ°æµ‹è¯•æœåŠ¡å™¨å¹¶æ›´æ–°
ssh -i /Users/chengjie/Downloads/chengjie.pem root@45.78.223.205
cd ~/rag-api
git pull origin main

# 5. ä»£ç å˜æ›´ç«‹å³ç”Ÿæ•ˆï¼ˆå¼€å‘æ¨¡å¼çƒ­é‡è½½ï¼‰
# ä»…åœ¨ä¿®æ”¹ä¾èµ–æˆ–é…ç½®æ—¶éœ€è¦é‡å¯ï¼š
docker compose -f docker-compose.dev.yml restart  # ä»…åœ¨éœ€è¦æ—¶
```

### Quick Deployment Commands

```bash
# å¿«é€Ÿéƒ¨ç½²åˆ°æµ‹è¯•æœåŠ¡å™¨ï¼ˆPR åˆå¹¶åŽï¼‰
git push && ssh -i /Users/chengjie/Downloads/chengjie.pem root@45.78.223.205 "cd ~/rag-api && git pull origin main"
```

**Important Notes**:
- æµ‹è¯•æœåŠ¡å™¨ä½¿ç”¨**å¼€å‘æ¨¡å¼** (docker-compose.dev.yml) æ”¯æŒçƒ­é‡è½½
- ä»£ç å˜æ›´ (src/, api/, main.py) **ç«‹å³ç”Ÿæ•ˆ**ï¼Œæ— éœ€é‡æ–°æž„å»º
- å§‹ç»ˆå…ˆæŽ¨é€åˆ° GitHubï¼Œå†éƒ¨ç½²åˆ°æµ‹è¯•æœåŠ¡å™¨
- ç¦æ­¢ç›´æŽ¥åœ¨æµ‹è¯•æœåŠ¡å™¨ä¸Šæäº¤ä»£ç 
- SSH å¯†é’¥éœ€è¦æ­£ç¡®æƒé™ï¼š`chmod 600 /Users/chengjie/Downloads/chengjie.pem`
- æ‰€æœ‰å¼€å‘é€šè¿‡åŠŸèƒ½åˆ†æ”¯ + PR æµç¨‹å®Œæˆ

## Configuration

Environment variables are managed through `.env` (copy from `env.example`):

### Required Configuration
- **ARK_API_KEY / ARK_BASE_URL / ARK_MODEL**: LLM for text generation and entity extraction
- **SF_API_KEY / SF_BASE_URL / SF_EMBEDDING_MODEL**: Embedding service (4096-dim vectors)
- **RERANK_MODEL**: Optional reranker model to improve retrieval relevance

### MinerU Modes
- **local**: Runs MinerU locally (requires GPU, high memory)
- **remote**: Uses remote MinerU API (recommended, saves resources)
  - Requires **MINERU_API_TOKEN** and **FILE_SERVICE_BASE_URL**
  - Model version: `pipeline` (stable) or `vlm` (faster, more accurate, recommended)

### External Storage Configuration

**Important**: LightRAG 1.4.9.4 uses **environment variables** for external storage configuration, not initialization parameters.

To enable external storage:

1. **Set storage toggle**:
   ```bash
   USE_EXTERNAL_STORAGE=true
   KV_STORAGE=RedisKVStorage
   VECTOR_STORAGE=PGVectorStorage
   GRAPH_STORAGE=Neo4JStorage
   ```

2. **Configure Redis** (for KV storage):
   ```bash
   REDIS_URI=redis://redis:6379/0  # URI format required
   REDIS_WORKSPACE=default          # Optional
   ```

3. **Configure PostgreSQL** (for vector storage):
   ```bash
   POSTGRES_HOST=postgres
   POSTGRES_PORT=5432
   POSTGRES_DATABASE=lightrag       # Note: POSTGRES_DATABASE not POSTGRES_DB
   POSTGRES_USER=lightrag
   POSTGRES_PASSWORD=your_password
   POSTGRES_WORKSPACE=default
   POSTGRES_MAX_CONNECTIONS=20
   ```

4. **Configure Neo4j** (for graph storage):
   ```bash
   NEO4J_URI=bolt://neo4j:7687
   NEO4J_USERNAME=neo4j
   NEO4J_PASSWORD=your_password
   NEO4J_WORKSPACE=default
   ```

**Key Points**:
- âœ… Storage backends read connection info from environment variables
- âŒ Do NOT pass `*_cls_kwargs` parameters to LightRAG.__init__()
- ðŸ“ See `env.example` for complete configuration template

### Performance Tuning

**Current configuration is optimized for EC2 persistent containers.**

#### Core Parameters
- **TOP_K**: Number of entities/relations to retrieve (default: 20, was 60)
- **CHUNK_TOP_K**: Number of text chunks to retrieve (default: 10, was 20)
- **MAX_ASYNC**: LLM concurrent requests (default: 8, optimized from 4)
- **DOCUMENT_PROCESSING_CONCURRENCY**: Concurrent document processing (1 for local, 10+ for remote)

#### Deployment-Specific Recommendations

**EC2/ECS Persistent Containers** (Current setup):
- `MAX_ASYNC=8`: Fully leverage persistent HTTP connections
- Worker warmup: Enabled in `src/rag.py:lifespan()` to reduce first query delay
- Expected performance: First query ~15s (after warmup), subsequent queries 6-11s
- Best for: Stable traffic (>5 req/hour), 7x24 services

**Fargate Auto-Scaling** (Alternative):
- `MAX_ASYNC=4`: Reduce cold start overhead
- Worker warmup: Still beneficial but less effective due to frequent container restarts
- Expected performance: First query ~35s, subsequent queries 10-15s
- Best for: Variable traffic, cost optimization for low-frequency usage

**Lambda/Serverless** (Not recommended):
- Worker initialization delay (25-35s per cold start) significantly impacts user experience
- HTTP connection pooling ineffective due to short container lifetime
- See `docs/LIGHTRAG_WORKER_MECHANISM_SOURCE_CODE_ANALYSIS.md` for detailed analysis

## Architecture Notes

### Single LightRAG + Multiple Parsers Pattern

The system uses a **shared LightRAG instance** (`global_lightrag_instance` in `src/rag.py:26`) that all parsers write to:

1. **Document Insertion** (`/insert` endpoint in `api/insert.py`):
   - Routes through RAGAnything parsers (MinerU or Docling)
   - Parser selection: automatic based on file type/size, or manual
   - Text files (.txt, .md) bypass parsers and insert directly to LightRAG
   - Remote MinerU mode: uploads file to file service, calls remote API, processes markdown result

2. **Query** (`/query` endpoint in `api/query.py`):
   - **Directly accesses LightRAG** via `get_lightrag_instance()`
   - Bypasses all parsers for optimal query performance
   - Solves read/write concurrency conflicts
   - Query modes: `naive` (fastest, 15-20s), `local`, `global`, `hybrid`, `mix` (slowest, most comprehensive)
   - **Advanced parameters** (aligned with LightRAG official API):
     - `conversation_history`: Multi-turn dialogue support
     - `user_prompt`: Custom prompt templates
     - `response_type`: Output format (paragraph/list/json)
     - `only_need_context`: Debug mode (returns context only)
     - `hl_keywords`/`ll_keywords`: Keyword extraction control
     - `max_entity_tokens`/`max_relation_tokens`/`max_total_tokens`: Token limits
   - **Stream query** (`/query/stream`): SSE-based real-time result streaming

3. **Task Management** (`api/task.py`, `api/task_store.py`):
   - Async background processing with FastAPI BackgroundTasks
   - Task statuses: `pending`, `processing`, `completed`, `failed`
   - Shared in-memory `TASK_STORE` for status tracking
   - `BATCH_STORE` for batch task mapping (fixed prefix matching bug)
   - Semaphore-based concurrency control (`DOCUMENT_PROCESSING_SEMAPHORE`)

### File Service for Remote MinerU

When `MINERU_MODE=remote`, the system:
1. Uploads files to temporary HTTP-accessible storage (`src/file_url_service.py`)
2. Passes file URLs to remote MinerU API (`src/mineru_client.py`)
3. Polls for completion and processes markdown results (`src/mineru_result_processor.py`)
4. Auto-cleanup of temporary files after configurable retention period

### Parser Selection Logic

Implemented in `src/rag.py:select_parser_by_file()`:
- **Text files (.txt, .md)**: Returns `None` (direct LightRAG insertion, no parser needed)
- **Images (.jpg, .png)**: MinerU (OCR capability)
- **PDF/Office < 500KB**: Docling (fast)
- **PDF/Office > 500KB**: MinerU (powerful)

**Note**: Function signature changed to `str | None` return type to explicitly indicate when no parser is needed.

## Multi-Tenant Usage

**All API endpoints require `tenant_id` parameter:**

```bash
# Query
POST /query?tenant_id=your_tenant_id

# Document upload
POST /insert?tenant_id=your_tenant_id

# Task status
GET /task/{task_id}?tenant_id=your_tenant_id
```

### Tenant Isolation

- **Data isolation**: Each tenant's documents and queries are completely isolated
- **Workspace-based**: Uses LightRAG's native workspace mechanism
- **External storage**: Redis/PostgreSQL/Neo4j with tenant-specific namespaces
  - Redis: `tenant_a:kv_store`
  - PostgreSQL: `tenant_a:vectors`
  - Neo4j: `tenant_a:GraphDB`

### Tenant Management

- **GET /tenants/stats?tenant_id=xxx**: Get tenant statistics
- **DELETE /tenants/cache?tenant_id=xxx**: Clear tenant instance cache
- **GET /tenants/pool/stats**: Get instance pool statistics (admin)

## API Routes

All routes are organized in `api/` directory and registered via `api/__init__.py`:

- **Document Processing**: `api/insert.py`
  - `POST /insert?tenant_id=xxx`: Single document upload (returns task_id)
  - `POST /batch?tenant_id=xxx`: Batch document upload (up to 100 files)
  - `GET /batch/{batch_id}?tenant_id=xxx`: Check batch progress

- **Query**: `api/query.py`
  - `POST /query?tenant_id=xxx`: Query the knowledge graph (supports 8 advanced parameters)
  - `POST /query/stream?tenant_id=xxx`: Stream query results via SSE (Server-Sent Events)

- **Task Management**: `api/task.py`
  - `GET /task/{task_id}?tenant_id=xxx`: Get task status

- **Tenant Management**: `api/tenant.py`
  - `GET /tenants/stats?tenant_id=xxx`: Get tenant statistics
  - `DELETE /tenants/cache?tenant_id=xxx`: Clear tenant cache
  - `GET /tenants/pool/stats`: Get instance pool statistics

- **File Service**: `api/files.py`
  - `GET /files/{file_id}/{filename}`: Download temporary files (for remote MinerU)

- **Performance Monitoring**: `api/monitor.py`
  - System metrics collection via `src/metrics.py`

## Important Implementation Details

### Multi-Tenant Architecture

**Core Components**:
- `src/multi_tenant.py`: Multi-tenant instance manager (LRU cache)
- `src/tenant_deps.py`: FastAPI dependency for tenant identification
- `api/tenant.py`: Tenant management endpoints

**Lifespan Management** (`src/rag.py:lifespan()`):
- Initializes multi-tenant manager (lazy loading)
- No shared LightRAG instance created at startup
- Tenant instances created on-demand (first request)
- Starts file cleanup background task
- Starts performance monitoring

**Tenant Instance Lifecycle**:
1. First request: Create LightRAG instance with `workspace=tenant_id`
2. Subsequent requests: Reuse cached instance
3. Pool full: Remove oldest instance (LRU strategy)
4. Manual cleanup: `DELETE /tenants/cache?tenant_id=xxx`

### Logging
Unified logging via `src/logger.py` using loguru:
- Structured JSON logs for production
- Automatic log rotation based on `LOG_RETENTION_DAYS`
- Log level controlled by `LOG_LEVEL` env var

### Error Handling in Document Processing
`api/insert.py:process_document_task()` handles:
- **MineruExecutionError**: Unsupported file format
- **ValueError**: Empty files, validation errors
- **OSError**: File system errors
- Always cleans up temporary files in `finally` block

### Performance Optimizations Applied
1. Reduced `TOP_K` from 60 to 20 (fewer entities retrieved)
2. Reduced `CHUNK_TOP_K` from 20 to 10 (fewer text chunks)
3. Increased `MAX_ASYNC` from 4 to 8 (faster entity merging)
4. Enabled rerank for better relevance (adds 2-3s but improves quality)
5. Direct LightRAG query path (bypasses parser overhead)

## Cursor Rules

From `.cursor/rules/docs-rules.mdc`:
- All documentation files must be placed in `docs/` folder

## Common Pitfalls

1. **multimodal_processed errors**: Delete `./rag_local_storage` to clear corrupted state
2. **Remote MinerU failures**: Verify `FILE_SERVICE_BASE_URL` is set to public IP:8000, not localhost
3. **Memory issues with local MinerU**: Switch to `MINERU_MODE=remote` or reduce `DOCUMENT_PROCESSING_CONCURRENCY` to 1
4. **Slow queries (75s+)**: Increase `MAX_ASYNC` in `.env` or use `naive` query mode instead of `mix`
5. **Empty file uploads**: API returns 400 with detailed error message

## File Structure

```
rag-api/
â”œâ”€â”€ main.py              # FastAPI app entry point
â”œâ”€â”€ api/                 # API route modules
â”‚   â”œâ”€â”€ __init__.py      # Router aggregation (includes tenant router)
â”‚   â”œâ”€â”€ insert.py        # Document insertion endpoints (multi-tenant)
â”‚   â”œâ”€â”€ query.py         # Query endpoints (multi-tenant)
â”‚   â”œâ”€â”€ task.py          # Task status endpoints (multi-tenant)
â”‚   â”œâ”€â”€ tenant.py        # Tenant management endpoints (NEW)
â”‚   â”œâ”€â”€ files.py         # File service endpoints
â”‚   â”œâ”€â”€ monitor.py       # Performance monitoring endpoints
â”‚   â”œâ”€â”€ models.py        # Pydantic models
â”‚   â””â”€â”€ task_store.py    # In-memory task tracking (tenant-isolated)
â”œâ”€â”€ src/                 # Core business logic
â”‚   â”œâ”€â”€ rag.py           # Multi-tenant lifecycle management
â”‚   â”œâ”€â”€ multi_tenant.py  # Multi-tenant instance manager (NEW)
â”‚   â”œâ”€â”€ tenant_deps.py   # Tenant dependency injection (NEW)
â”‚   â”œâ”€â”€ logger.py        # Unified logging
â”‚   â”œâ”€â”€ metrics.py       # Performance metrics collection
â”‚   â”œâ”€â”€ file_url_service.py        # Temporary file HTTP service
â”‚   â”œâ”€â”€ mineru_client.py           # Remote MinerU API client
â”‚   â””â”€â”€ mineru_result_processor.py # MinerU result processor
â”œâ”€â”€ scripts/             # Maintenance and test scripts
â”œâ”€â”€ docs/                # Documentation (per Cursor rules)
â””â”€â”€ rag_local_storage/   # LightRAG working directory (git-ignored)
```

## Recent Optimizations (2025-10-30)

### API Enhancement & Code Refactoring

**Completed improvements** to align with LightRAG official API while maintaining multi-tenant advantages:

1. **Query Enhancement** (`api/query.py`, `api/models.py`):
   - Added 8 advanced parameters aligned with LightRAG official API
   - Support for multi-turn dialogue (`conversation_history`)
   - Custom prompt templates (`user_prompt`)
   - Response format control (`response_type`: paragraph/list/json)
   - Debug mode (`only_need_context`)
   - Keyword extraction control (`hl_keywords`, `ll_keywords`)
   - Token limits (`max_entity_tokens`, `max_relation_tokens`, `max_total_tokens`)

2. **Stream Query** (`api/query.py`):
   - New endpoint: `POST /query/stream`
   - SSE (Server-Sent Events) format for real-time streaming
   - Dual mode: native streaming + fallback chunking
   - Automatic `<think>` tag removal for clean output

3. **Parser Selection Optimization** (`src/rag.py`):
   - Changed `select_parser_by_file()` return type from `str` to `str | None`
   - Text files (.txt, .md) now return `None` explicitly (no parser needed)
   - More accurate logging: `direct_insert` instead of misleading `mineru`

4. **Batch Task Tracking Fix** (`api/task_store.py`, `api/insert.py`):
   - Added `BATCH_STORE` to replace unreliable prefix matching
   - Functions: `create_batch()`, `get_batch()`, `delete_batch()`
   - 100% accurate batch task mapping

5. **File Extension Check Simplification** (`api/insert.py`):
   - Removed unnecessary security validation
   - Simplified from 7 lines to 1 line
   - UUID-based filename ensures security

6. **Documentation**:
   - Created `docs/API_COMPARISON.md`: Comprehensive comparison with LightRAG official API
   - Updated `docs/LIGHTRAG_WEBUI_INTEGRATION.md`: Multi-tenant limitations and roadmap
   - **Key finding**: All 17 rag-api endpoints have differentiated value, 0 can be deleted

### Why rag-api Still Matters

Despite LightRAG official API's feature richness, rag-api provides **irreplaceable value**:

- **Multi-tenant architecture**: LRU instance pool, workspace-based isolation
- **Strong document parsing**: MinerU (OCR/tables/formulas) + Docling smart routing
- **Batch processing**: `/batch` endpoint (up to 100 files)
- **Production operations**: Tenant management, cache control, performance monitoring
- **Extensibility**: Easy to add custom business logic

See `docs/API_COMPARISON.md` for detailed analysis.
